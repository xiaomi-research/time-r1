[
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/KWZSA.mp4",
        "question": "a person was sitting at a table.",
        "answer": "13.4-28.1",
        "start": null,
        "end": null,
        "duration": 30.12,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 6,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/OHOFG.mp4",
        "question": "person sitting down in a chair.",
        "answer": "1.0-7.5",
        "start": null,
        "end": null,
        "duration": 35.04,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/4K0BP.mp4",
        "question": "person drinks a glass of water from the shelf.",
        "answer": "8.6-17.7",
        "start": null,
        "end": null,
        "duration": 30.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/P6JGZ.mp4",
        "question": "person opening a cabinet.",
        "answer": "0.0-4.4",
        "start": null,
        "end": null,
        "duration": 11.46,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/QZZPS.mp4",
        "question": "a person is seen sitting on a couch.",
        "answer": "0.0-12.8",
        "start": null,
        "end": null,
        "duration": 31.29,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/ZDWM7.mp4",
        "question": "person talking on the phone.",
        "answer": "0.0-9.3",
        "start": null,
        "end": null,
        "duration": 30.42,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/3P055.mp4",
        "question": "a person is dressing in front of a mirror.",
        "answer": "7.5-27.7",
        "start": null,
        "end": null,
        "duration": 43.0,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 4,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/EXYY8.mp4",
        "question": "person closing the door behind them.",
        "answer": "14.1-20.0",
        "start": null,
        "end": null,
        "duration": 19.29,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/BLWIW.mp4",
        "question": "person looking out the window.",
        "answer": "13.0-19.0",
        "start": null,
        "end": null,
        "duration": 17.58,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 0,
            "qcenter": 9,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/OB660.mp4",
        "question": "person run over to the window to look outside.",
        "answer": "0.0-5.6",
        "start": null,
        "end": null,
        "duration": 14.42,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/4BEZX.mp4",
        "question": "person sit down in a chair.",
        "answer": "39.6-44.0",
        "start": null,
        "end": null,
        "duration": 43.29,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/RBQ9Y.mp4",
        "question": "person putting away clothes in a bedroom.",
        "answer": "53.2-59.0",
        "start": null,
        "end": null,
        "duration": 58.33,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/NI15V.mp4",
        "question": "person holding a towel in the other hand.",
        "answer": "13.5-19.5",
        "start": null,
        "end": null,
        "duration": 30.58,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 5,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/1XBU2.mp4",
        "question": "person is drinking tea from glass mug.",
        "answer": "4.3-10.9",
        "start": null,
        "end": null,
        "duration": 16.58,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/86E2E.mp4",
        "question": "person snuggling with a pillow.",
        "answer": "2.2-8.2",
        "start": null,
        "end": null,
        "duration": 19.83,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 2,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/G2JR9.mp4",
        "question": "person the lightbulb lights up.",
        "answer": "20.7-25.6",
        "start": null,
        "end": null,
        "duration": 31.0,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/QQGU3.mp4",
        "question": "the person opens the doors to the cupboard.",
        "answer": "0.0-5.3",
        "start": null,
        "end": null,
        "duration": 18.04,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/0TKKR.mp4",
        "question": "person they pour a drink in a glass.",
        "answer": "30.7-41.5",
        "start": null,
        "end": null,
        "duration": 44.0,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/BEAAA.mp4",
        "question": "person sitting in a chair eating.",
        "answer": "0.0-3.5",
        "start": null,
        "end": null,
        "duration": 27.96,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 1,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "charades",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/31YNM.mp4",
        "question": "the person drinks from a cup from the side table.",
        "answer": "11.7-24.4",
        "start": null,
        "end": null,
        "duration": 30.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 5,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/G2QBV.mp4",
        "question": "a person throws a broom into the corner.",
        "answer": "11.3-19.9",
        "start": null,
        "end": null,
        "duration": 30.21,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 5,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/OZ02A.mp4",
        "question": "person a light is turned on.",
        "answer": "2.9-11.8",
        "start": null,
        "end": null,
        "duration": 40.79,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 2,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/Q5MDU.mp4",
        "question": "person turning on a light.",
        "answer": "0.0-3.6",
        "start": null,
        "end": null,
        "duration": 9.25,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/422BV.mp4",
        "question": "person holding shoes.",
        "answer": "0.0-9.4",
        "start": null,
        "end": null,
        "duration": 20.29,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/RG0JH.mp4",
        "question": "a person is sitting on the bed.",
        "answer": "0.0-8.1",
        "start": null,
        "end": null,
        "duration": 17.29,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 0,
            "qcenter": 2,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/M6HAF.mp4",
        "question": "person open the refrigerator door.",
        "answer": "0.0-4.2",
        "start": null,
        "end": null,
        "duration": 11.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/S4P5J.mp4",
        "question": "person putting away groceries.",
        "answer": "5.9-24.8",
        "start": null,
        "end": null,
        "duration": 41.46,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/HXUI5.mp4",
        "question": "a person is also dressing.",
        "answer": "13.4-28.7",
        "start": null,
        "end": null,
        "duration": 47.88,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/7O6FK.mp4",
        "question": "person takes a picture from the wall.",
        "answer": "9.3-14.5",
        "start": null,
        "end": null,
        "duration": 19.0,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 6,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/1FIGA.mp4",
        "question": "person put something in it closes the door.",
        "answer": "18.1-24.9",
        "start": null,
        "end": null,
        "duration": 35.75,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 1,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/0UPBN.mp4",
        "question": "person holding a box.",
        "answer": "19.3-31.8",
        "start": null,
        "end": null,
        "duration": 33.46,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/TUD6M.mp4",
        "question": "person throws their blanket inside.",
        "answer": "4.3-8.0",
        "start": null,
        "end": null,
        "duration": 7.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 8,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/IGZZG.mp4",
        "question": "the person is sitting on the floor watching television.",
        "answer": "5.4-11.6",
        "start": null,
        "end": null,
        "duration": 18.42,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/XRG9K.mp4",
        "question": "person takes something out box.",
        "answer": "5.5-11.5",
        "start": null,
        "end": null,
        "duration": 18.96,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/A1BS2.mp4",
        "question": "person they open a cabinet.",
        "answer": "14.0-20.1",
        "start": null,
        "end": null,
        "duration": 47.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/NKE77.mp4",
        "question": "person puts it down on the table.",
        "answer": "8.2-14.8",
        "start": null,
        "end": null,
        "duration": 30.75,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 3,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/AKU63.mp4",
        "question": "a person lies sleeping on a bed.",
        "answer": "0.6-10.7",
        "start": null,
        "end": null,
        "duration": 34.88,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/G2JR9.mp4",
        "question": "person the light turns on.",
        "answer": "20.7-25.6",
        "start": null,
        "end": null,
        "duration": 31.0,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/RAGOI.mp4",
        "question": "person as they stand up to grab a towel.",
        "answer": "2.7-7.2",
        "start": null,
        "end": null,
        "duration": 10.92,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/DR1ZU.mp4",
        "question": "a person turns on the light.",
        "answer": "2.1-7.6",
        "start": null,
        "end": null,
        "duration": 13.54,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/CUQYX.mp4",
        "question": "person take off their shoes.",
        "answer": "4.7-17.8",
        "start": null,
        "end": null,
        "duration": 30.58,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 3,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/F3M1Q.mp4",
        "question": "person throws them on the floor.",
        "answer": "0.7-6.0",
        "start": null,
        "end": null,
        "duration": 16.04,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 2,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/S4P5J.mp4",
        "question": "another person is smiling.",
        "answer": "33.7-38.5",
        "start": null,
        "end": null,
        "duration": 41.46,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 1,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/3LMTS.mp4",
        "question": "person holding the phone in between their shoulder.",
        "answer": "16.3-31.0",
        "start": null,
        "end": null,
        "duration": 30.29,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/15PMU.mp4",
        "question": "person looking out the window.",
        "answer": "0.9-12.4",
        "start": null,
        "end": null,
        "duration": 30.88,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/SM41Q.mp4",
        "question": "person takes a laptop.",
        "answer": "3.7-13.0",
        "start": null,
        "end": null,
        "duration": 19.0,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/BFCU9.mp4",
        "question": "person the put the food down.",
        "answer": "3.2-8.4",
        "start": null,
        "end": null,
        "duration": 17.46,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/ST7MR.mp4",
        "question": "person they throw it on the floor.",
        "answer": "28.3-35.7",
        "start": null,
        "end": null,
        "duration": 48.42,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/Q5YDL.mp4",
        "question": "person playing a game on a laptop.",
        "answer": "0.0-16.5",
        "start": null,
        "end": null,
        "duration": 50.83,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/N6FZ7.mp4",
        "question": "a person runs into the living room.",
        "answer": "0.0-6.4",
        "start": null,
        "end": null,
        "duration": 18.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/TS2DM.mp4",
        "question": "person still smiling.",
        "answer": "0.0-15.7",
        "start": null,
        "end": null,
        "duration": 31.83,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/AGGSE.mp4",
        "question": "the person is sneezing.",
        "answer": "8.9-15.0",
        "start": null,
        "end": null,
        "duration": 28.08,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 4,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/VQOI3.mp4",
        "question": "person opening a bag.",
        "answer": "0.0-3.6",
        "start": null,
        "end": null,
        "duration": 17.75,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/Q7IQI.mp4",
        "question": "a person is sneezing into a blanket.",
        "answer": "1.8-8.6",
        "start": null,
        "end": null,
        "duration": 17.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/6TC5G.mp4",
        "question": "person throws the rest on the floor below them.",
        "answer": "12.3-17.5",
        "start": null,
        "end": null,
        "duration": 17.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/BZ5N5.mp4",
        "question": "the person takes two glasses from the cabinet.",
        "answer": "2.2-16.8",
        "start": null,
        "end": null,
        "duration": 33.54,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/KE5EM.mp4",
        "question": "person begins sneezing.",
        "answer": "6.3-10.9",
        "start": null,
        "end": null,
        "duration": 12.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 6,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/3WMV4.mp4",
        "question": "a person is eating.",
        "answer": "3.1-9.1",
        "start": null,
        "end": null,
        "duration": 17.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/QQMY8.mp4",
        "question": "person grabs a cup turns off the light.",
        "answer": "9.8-14.0",
        "start": null,
        "end": null,
        "duration": 13.29,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 0,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/DV6CH.mp4",
        "question": "a person opens their closet.",
        "answer": "0.0-6.2",
        "start": null,
        "end": null,
        "duration": 31.83,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/CUQYX.mp4",
        "question": "person they take off their shoes.",
        "answer": "4.7-17.8",
        "start": null,
        "end": null,
        "duration": 30.58,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 3,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/9JZO2.mp4",
        "question": "person puts on some shoes.",
        "answer": "26.1-36.0",
        "start": null,
        "end": null,
        "duration": 35.75,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/50E06.mp4",
        "question": "a person in their recreation room is eating some food.",
        "answer": "0.0-5.1",
        "start": null,
        "end": null,
        "duration": 32.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/KO2MY.mp4",
        "question": "a person laughs to themselves.",
        "answer": "2.5-10.9",
        "start": null,
        "end": null,
        "duration": 19.67,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/SJJLG.mp4",
        "question": "person sits on a chair.",
        "answer": "10.8-15.8",
        "start": null,
        "end": null,
        "duration": 16.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 7,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/HI75B.mp4",
        "question": "person opens a cabinet under the stairs.",
        "answer": "3.9-10.4",
        "start": null,
        "end": null,
        "duration": 17.62,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/79VVK.mp4",
        "question": "a person takes a blanket.",
        "answer": "15.1-20.4",
        "start": null,
        "end": null,
        "duration": 40.08,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/TKAUR.mp4",
        "question": "person start dressing for the weather.",
        "answer": "27.0-40.3",
        "start": null,
        "end": null,
        "duration": 41.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/0TDOP.mp4",
        "question": "a person holding a brown cardboard box enters a kitchen.",
        "answer": "0.0-6.7",
        "start": null,
        "end": null,
        "duration": 30.42,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/FSOFF.mp4",
        "question": "person proceeds to take their shoes off.",
        "answer": "11.8-21.0",
        "start": null,
        "end": null,
        "duration": 19.79,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 8,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/LSCMZ.mp4",
        "question": "the person takes a phone from somewhere.",
        "answer": "13.7-19.0",
        "start": null,
        "end": null,
        "duration": 18.46,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/HI4NV.mp4",
        "question": "person holding some food on some dishes.",
        "answer": "3.4-18.3",
        "start": null,
        "end": null,
        "duration": 30.04,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 3,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/EYZXC.mp4",
        "question": "person pours a cup of coffee.",
        "answer": "8.9-23.2",
        "start": null,
        "end": null,
        "duration": 41.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/FFYL6.mp4",
        "question": "a person puts a broom into the closet.",
        "answer": "0.0-6.3",
        "start": null,
        "end": null,
        "duration": 13.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 2,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/T5SI3.mp4",
        "question": "person starts to close the box.",
        "answer": "9.3-15.0",
        "start": null,
        "end": null,
        "duration": 13.58,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 8,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/RXELU.mp4",
        "question": "person turns the light on.",
        "answer": "2.5-6.6",
        "start": null,
        "end": null,
        "duration": 14.88,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/3MX8V.mp4",
        "question": "the person throws a sweater on the floor.",
        "answer": "0.0-5.5",
        "start": null,
        "end": null,
        "duration": 31.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/QMHK8.mp4",
        "question": "person walks into room holding a bag.",
        "answer": "0.0-16.7",
        "start": null,
        "end": null,
        "duration": 58.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/JKWJ6.mp4",
        "question": "a person is lying on the couch watching television.",
        "answer": "0.0-9.5",
        "start": null,
        "end": null,
        "duration": 31.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/FQM2N.mp4",
        "question": "person sitting on the bed.",
        "answer": "0.0-3.2",
        "start": null,
        "end": null,
        "duration": 34.54,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/86E2E.mp4",
        "question": "the person is sitting on the floor.",
        "answer": "0.0-8.8",
        "start": null,
        "end": null,
        "duration": 19.83,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 0,
            "qcenter": 2,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/V8IGX.mp4",
        "question": "person begins sitting on the sofa.",
        "answer": "20.2-28.0",
        "start": null,
        "end": null,
        "duration": 26.92,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/YNWMW.mp4",
        "question": "a person is in a basement eating.",
        "answer": "0.0-5.2",
        "start": null,
        "end": null,
        "duration": 16.29,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/KERO6.mp4",
        "question": "the person puts some food onto a pan.",
        "answer": "11.4-16.9",
        "start": null,
        "end": null,
        "duration": 40.08,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/1NJOQ.mp4",
        "question": "a person walks through the doorway.",
        "answer": "0.0-5.9",
        "start": null,
        "end": null,
        "duration": 34.96,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/WKVWF.mp4",
        "question": "person takes things out of a box.",
        "answer": "19.7-30.0",
        "start": null,
        "end": null,
        "duration": 29.08,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 8,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/DR7K0.mp4",
        "question": "person begin to dress themselves.",
        "answer": "17.3-32.0",
        "start": null,
        "end": null,
        "duration": 31.33,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/0A8CF.mp4",
        "question": "person drinks from a glass of water.",
        "answer": "25.5-33.0",
        "start": null,
        "end": null,
        "duration": 32.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 9,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/8B4ZP.mp4",
        "question": "person start undressing.",
        "answer": "38.4-47.8",
        "start": null,
        "end": null,
        "duration": 48.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/P5YNX.mp4",
        "question": "a person is sitting in a chair.",
        "answer": "0.0-13.1",
        "start": null,
        "end": null,
        "duration": 29.54,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/AYZS4.mp4",
        "question": "a person eats a banana.",
        "answer": "4.2-17.9",
        "start": null,
        "end": null,
        "duration": 49.62,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/M6HAF.mp4",
        "question": "the person opens the refrigerator.",
        "answer": "0.0-4.2",
        "start": null,
        "end": null,
        "duration": 11.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/GG3K5.mp4",
        "question": "the person start watching television.",
        "answer": "19.5-31.0",
        "start": null,
        "end": null,
        "duration": 31.96,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/JVOM3.mp4",
        "question": "person a flashlight by the doorway.",
        "answer": "4.7-9.4",
        "start": null,
        "end": null,
        "duration": 38.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "charades",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/3HRNV.mp4",
        "question": "a person is smiling in a study holding a bag.",
        "answer": "0.3-4.8",
        "start": null,
        "end": null,
        "duration": 15.58,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/MS4GA.mp4",
        "question": "a person opens a closet door.",
        "answer": "5.4-11.5",
        "start": null,
        "end": null,
        "duration": 29.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/2RFLZ.mp4",
        "question": "a person picks up their phone talks on it.",
        "answer": "3.0-10.4",
        "start": null,
        "end": null,
        "duration": 14.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/OB660.mp4",
        "question": "person runs to look out the window.",
        "answer": "0.0-5.6",
        "start": null,
        "end": null,
        "duration": 14.42,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/OZ02A.mp4",
        "question": "the person turned on the light in the dining room.",
        "answer": "2.9-11.8",
        "start": null,
        "end": null,
        "duration": 40.79,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/W3NN2.mp4",
        "question": "person turns off the light.",
        "answer": "26.7-31.0",
        "start": null,
        "end": null,
        "duration": 29.67,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 9,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/QLGHA.mp4",
        "question": "a smiling person is putting a broom in the pantry.",
        "answer": "3.3-10.0",
        "start": null,
        "end": null,
        "duration": 31.29,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/WX711.mp4",
        "question": "person drinking out of a cup.",
        "answer": "14.8-22.5",
        "start": null,
        "end": null,
        "duration": 30.75,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 6,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/VFAE3.mp4",
        "question": "person a girl walks past his doorway.",
        "answer": "0.0-5.2",
        "start": null,
        "end": null,
        "duration": 39.75,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/E89S9.mp4",
        "question": "a person is sitting on a chair.",
        "answer": "0.0-8.9",
        "start": null,
        "end": null,
        "duration": 20.58,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/JT537.mp4",
        "question": "person put the broom down.",
        "answer": "16.9-23.1",
        "start": null,
        "end": null,
        "duration": 26.54,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/JR6VG.mp4",
        "question": "person the door opens.",
        "answer": "8.0-15.1",
        "start": null,
        "end": null,
        "duration": 22.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 5,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/HIKIC.mp4",
        "question": "the person opens a box.",
        "answer": "0.9-7.7",
        "start": null,
        "end": null,
        "duration": 30.67,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/9PXI9.mp4",
        "question": "person stand up.",
        "answer": "10.5-16.4",
        "start": null,
        "end": null,
        "duration": 30.79,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/W3NN2.mp4",
        "question": "person turned off the light.",
        "answer": "26.7-31.0",
        "start": null,
        "end": null,
        "duration": 29.67,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 1,
            "qcenter": 9,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/Y8L60.mp4",
        "question": "a person opens a small cabinet door.",
        "answer": "0.0-4.1",
        "start": null,
        "end": null,
        "duration": 8.42,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 2,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/GCI2J.mp4",
        "question": "a person holds a camera up.",
        "answer": "0.0-11.8",
        "start": null,
        "end": null,
        "duration": 30.62,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/DR1ZU.mp4",
        "question": "person turns the light on.",
        "answer": "2.1-7.6",
        "start": null,
        "end": null,
        "duration": 13.54,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/02DPI.mp4",
        "question": "person drinking water from a glass.",
        "answer": "23.4-30.5",
        "start": null,
        "end": null,
        "duration": 41.25,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/DLOS7.mp4",
        "question": "person they sit down holding a laptop.",
        "answer": "11.7-16.9",
        "start": null,
        "end": null,
        "duration": 41.42,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/QQGU3.mp4",
        "question": "person opens the box.",
        "answer": "10.3-18.5",
        "start": null,
        "end": null,
        "duration": 18.04,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 7,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/1RD2K.mp4",
        "question": "another person comes running in.",
        "answer": "1.0-8.6",
        "start": null,
        "end": null,
        "duration": 19.83,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 2,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/CYCEV.mp4",
        "question": "another person is looking out the window.",
        "answer": "0.0-4.8",
        "start": null,
        "end": null,
        "duration": 30.79,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/3WMV4.mp4",
        "question": "person eating a sandwich.",
        "answer": "3.1-9.1",
        "start": null,
        "end": null,
        "duration": 17.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/Q6290.mp4",
        "question": "person watching the television eating an apple.",
        "answer": "0.0-8.3",
        "start": null,
        "end": null,
        "duration": 17.08,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 0,
            "qcenter": 2,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/3IPI3.mp4",
        "question": "the person eats a sandwich.",
        "answer": "7.9-13.0",
        "start": null,
        "end": null,
        "duration": 17.92,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 5,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/XMYXI.mp4",
        "question": "a man is sitting at a chair.",
        "answer": "0.0-7.0",
        "start": null,
        "end": null,
        "duration": 40.25,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 2,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/KE5EM.mp4",
        "question": "person opens it up to take some clothes out.",
        "answer": "4.6-9.3",
        "start": null,
        "end": null,
        "duration": 12.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 5,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/CEZ4D.mp4",
        "question": "person holding a broom on the stairs.",
        "answer": "27.8-35.0",
        "start": null,
        "end": null,
        "duration": 33.92,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 9,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/BFCU9.mp4",
        "question": "a person is eating from a can.",
        "answer": "0.2-5.3",
        "start": null,
        "end": null,
        "duration": 17.46,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/GZF5F.mp4",
        "question": "person pours another glass out of a pitcher.",
        "answer": "4.7-11.7",
        "start": null,
        "end": null,
        "duration": 16.92,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/DAA3F.mp4",
        "question": "person take some food.",
        "answer": "11.5-17.4",
        "start": null,
        "end": null,
        "duration": 32.0,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/BFCU9.mp4",
        "question": "person puts the jar down on a table.",
        "answer": "14.0-18.0",
        "start": null,
        "end": null,
        "duration": 17.46,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 9,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/TS2DM.mp4",
        "question": "person holding a cell phone.",
        "answer": "0.0-13.8",
        "start": null,
        "end": null,
        "duration": 31.83,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/QMHK8.mp4",
        "question": "person closes the door.",
        "answer": "0.9-14.1",
        "start": null,
        "end": null,
        "duration": 58.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/XRG9K.mp4",
        "question": "person opening box.",
        "answer": "1.7-9.4",
        "start": null,
        "end": null,
        "duration": 18.96,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 2,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/TJZ0P.mp4",
        "question": "the person is seated in a chair.",
        "answer": "10.2-19.0",
        "start": null,
        "end": null,
        "duration": 17.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 0,
            "qcenter": 8,
            "qlen": 7,
            "dataset": "charades",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/FJYZH.mp4",
        "question": "person eat a small snack they got from their pocket.",
        "answer": "12.1-19.0",
        "start": null,
        "end": null,
        "duration": 17.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 8,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/DGPAW.mp4",
        "question": "person opens the door.",
        "answer": "10.5-16.6",
        "start": null,
        "end": null,
        "duration": 16.54,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 8,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/7O6FK.mp4",
        "question": "person takes a picture frame off a wall.",
        "answer": "9.3-14.5",
        "start": null,
        "end": null,
        "duration": 19.0,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 6,
            "qlen": 4,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/BEJVY.mp4",
        "question": "a person is eating food in the man cave.",
        "answer": "2.4-8.1",
        "start": null,
        "end": null,
        "duration": 14.96,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 5,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/N0NLE.mp4",
        "question": "person laughs at cellphone.",
        "answer": "23.5-30.0",
        "start": null,
        "end": null,
        "duration": 29.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 9,
            "qlen": 3,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/E5ZF5.mp4",
        "question": "person eating food.",
        "answer": "6.0-12.3",
        "start": null,
        "end": null,
        "duration": 35.62,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/Charades/Charades_v1/HQ8BB.mp4",
        "question": "person turning the light on.",
        "answer": "2.5-9.2",
        "start": null,
        "end": null,
        "duration": 16.08,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/Charades_sta_test.json",
        "dataset_name": "charades",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 6,
            "dataset": "charades",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Gb-uDDzFRLE.mp4",
        "question": "take bottom and measure size",
        "answer": "17.0-32.0",
        "start": null,
        "end": null,
        "duration": 55.09,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Gb-uDDzFRLE.mp4",
        "question": "cut straight and well",
        "answer": "32.0-40.0",
        "start": null,
        "end": null,
        "duration": 55.09,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Gb-uDDzFRLE.mp4",
        "question": "cut as slide way",
        "answer": "40.0-49.0",
        "start": null,
        "end": null,
        "duration": 55.09,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/gqEbqMKoh9I.mp4",
        "question": "take paper and put soda onit",
        "answer": "33.0-51.0",
        "start": null,
        "end": null,
        "duration": 142.61,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 7,
            "qcenter": 2,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/gqEbqMKoh9I.mp4",
        "question": "fold paper with soda",
        "answer": "51.0-70.0",
        "start": null,
        "end": null,
        "duration": 142.61,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/gqEbqMKoh9I.mp4",
        "question": "put vinegar with sandwich bag",
        "answer": "70.0-89.0",
        "start": null,
        "end": null,
        "duration": 142.61,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/gqEbqMKoh9I.mp4",
        "question": "put vinegar paper on bag",
        "answer": "89.0-100.0",
        "start": null,
        "end": null,
        "duration": 142.61,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/gqEbqMKoh9I.mp4",
        "question": "shack it well",
        "answer": "100.0-104.0",
        "start": null,
        "end": null,
        "duration": 142.61,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/S6N5RpvChWs.mp4",
        "question": "take water with vinegar in plastic bags",
        "answer": "32.0-56.0",
        "start": null,
        "end": null,
        "duration": 155.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/S6N5RpvChWs.mp4",
        "question": "take baking soda in tissue paper",
        "answer": "56.0-94.0",
        "start": null,
        "end": null,
        "duration": 155.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 4,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/S6N5RpvChWs.mp4",
        "question": "fold paper well",
        "answer": "94.0-103.0",
        "start": null,
        "end": null,
        "duration": 155.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/S6N5RpvChWs.mp4",
        "question": "put it into the bag",
        "answer": "103.0-104.0",
        "start": null,
        "end": null,
        "duration": 155.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/S6N5RpvChWs.mp4",
        "question": "keep away to explode",
        "answer": "104.0-113.0",
        "start": null,
        "end": null,
        "duration": 155.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LKSvFmXLQA0.mp4",
        "question": "Make the fire to use cook",
        "answer": "27.0-37.0",
        "start": null,
        "end": null,
        "duration": 67.77,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LKSvFmXLQA0.mp4",
        "question": "Place large logs into bottom",
        "answer": "37.0-46.0",
        "start": null,
        "end": null,
        "duration": 67.77,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/aHDGMOQgHUE.mp4",
        "question": "make a fire with coal",
        "answer": "35.0-63.0",
        "start": null,
        "end": null,
        "duration": 99.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/aHDGMOQgHUE.mp4",
        "question": "check the gas",
        "answer": "9.944375536211354-45.94437553621135",
        "start": 53.05562446378865,
        "end": 152.42562446378867,
        "duration": 99.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 4,
            "qcenter": 2,
            "qlen": 5,
            "dataset": "hirest",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Tu9foJWCkgs.mp4",
        "question": "Remove lid",
        "answer": "47.0-57.0",
        "start": null,
        "end": null,
        "duration": 95.73,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Tu9foJWCkgs.mp4",
        "question": "Put handle",
        "answer": "42.70139379531047-48.70139379531047",
        "start": 4.4928652563499725,
        "end": 100.22286525634998,
        "duration": 95.73,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Tu9foJWCkgs.mp4",
        "question": "Pick grill to put stones",
        "answer": "63.0-72.0",
        "start": null,
        "end": null,
        "duration": 95.73,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 7,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Tu9foJWCkgs.mp4",
        "question": "Put the lid back",
        "answer": "34.07364259931223-44.07364259931223",
        "start": 37.92635740068777,
        "end": 133.65635740068777,
        "duration": 95.73,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/5Jn7OuXb0FA.mp4",
        "question": "Take your felt",
        "answer": "25.0-27.0",
        "start": null,
        "end": null,
        "duration": 112.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/5Jn7OuXb0FA.mp4",
        "question": "Draw your stencil",
        "answer": "27.0-35.0",
        "start": null,
        "end": null,
        "duration": 112.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/5Jn7OuXb0FA.mp4",
        "question": "Cut it out",
        "answer": "35.0-48.0",
        "start": null,
        "end": null,
        "duration": 112.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/5Jn7OuXb0FA.mp4",
        "question": "Lay it out first",
        "answer": "48.0-60.0",
        "start": null,
        "end": null,
        "duration": 112.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/5Jn7OuXb0FA.mp4",
        "question": "Glue the gems",
        "answer": "60.0-76.0",
        "start": null,
        "end": null,
        "duration": 112.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/5Jn7OuXb0FA.mp4",
        "question": "Glue the pin",
        "answer": "76.0-83.0",
        "start": null,
        "end": null,
        "duration": 112.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Ti9ibiKSpf8.mp4",
        "question": "Add mustard",
        "answer": "13.0-24.0",
        "start": null,
        "end": null,
        "duration": 89.86,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 2,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Ti9ibiKSpf8.mp4",
        "question": "Add honey",
        "answer": "24.0-38.0",
        "start": 0.0,
        "end": 89.86,
        "duration": 89.86,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Ti9ibiKSpf8.mp4",
        "question": "Add garlic",
        "answer": "38.0-46.0",
        "start": null,
        "end": null,
        "duration": 89.86,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Ti9ibiKSpf8.mp4",
        "question": "Add sriracha sauce",
        "answer": "45.30325929771263-51.30325929771263",
        "start": 0.6967407022873715,
        "end": 90.55674070228737,
        "duration": 89.86,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Ti9ibiKSpf8.mp4",
        "question": "Mix it",
        "answer": "52.0-79.0",
        "start": null,
        "end": null,
        "duration": 89.86,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 7,
            "qlen": 4,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/cQ0namNxwWA.mp4",
        "question": "prepare the ingredients",
        "answer": "99.0-108.0",
        "start": null,
        "end": null,
        "duration": 152.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/cQ0namNxwWA.mp4",
        "question": "beat the egg with cinnamon ",
        "answer": "108.0-111.0",
        "start": null,
        "end": null,
        "duration": 152.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/cQ0namNxwWA.mp4",
        "question": "add nutmeg with allspice to taste",
        "answer": "111.0-112.0",
        "start": null,
        "end": null,
        "duration": 152.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/cQ0namNxwWA.mp4",
        "question": "spread some almond meal on plate",
        "answer": "112.0-115.0",
        "start": null,
        "end": null,
        "duration": 152.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/cQ0namNxwWA.mp4",
        "question": "place ham on pineapple piece",
        "answer": "115.0-121.0",
        "start": null,
        "end": null,
        "duration": 152.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/cQ0namNxwWA.mp4",
        "question": "dip that to the beaten egg",
        "answer": "121.0-125.0",
        "start": null,
        "end": null,
        "duration": 152.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/cQ0namNxwWA.mp4",
        "question": "coat pineapple with almond meal",
        "answer": "125.0-129.0",
        "start": null,
        "end": null,
        "duration": 152.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/cQ0namNxwWA.mp4",
        "question": "coat ham with almond meal",
        "answer": "129.0-133.0",
        "start": null,
        "end": null,
        "duration": 152.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/cQ0namNxwWA.mp4",
        "question": "place on heated fry pan with oil",
        "answer": "133.0-134.0",
        "start": null,
        "end": null,
        "duration": 152.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/cQ0namNxwWA.mp4",
        "question": "cook until it has browned",
        "answer": "134.0-152.0",
        "start": null,
        "end": null,
        "duration": 152.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LX_VHvjunFM.mp4",
        "question": "things to make Krispie Buns",
        "answer": "4.0-21.0",
        "start": 0.0,
        "end": 86.5,
        "duration": 86.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 1,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LX_VHvjunFM.mp4",
        "question": "Put water in pan,mix chocloate ",
        "answer": "21.0-55.0",
        "start": null,
        "end": null,
        "duration": 86.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 5,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LX_VHvjunFM.mp4",
        "question": "Put the mix in cups",
        "answer": "34.55347136431934-36.55347136431934",
        "start": 20.446528635680657,
        "end": 106.94652863568066,
        "duration": 86.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/opGK2SjlWJU.mp4",
        "question": "cut the edges of turnip",
        "answer": "57.0-82.0",
        "start": null,
        "end": null,
        "duration": 103.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 6,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/opGK2SjlWJU.mp4",
        "question": "cut into small pieces",
        "answer": "82.0-97.0",
        "start": null,
        "end": null,
        "duration": 103.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 8,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/opGK2SjlWJU.mp4",
        "question": "cook with vinegar pepper salt",
        "answer": "97.0-103.0",
        "start": null,
        "end": null,
        "duration": 103.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/9pybtCnEqEQ.mp4",
        "question": "make grass using bottom of the ",
        "answer": "28.0-31.0",
        "start": null,
        "end": null,
        "duration": 148.4,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/9pybtCnEqEQ.mp4",
        "question": "using pencil draw grass",
        "answer": "31.0-54.0",
        "start": null,
        "end": null,
        "duration": 148.4,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/9pybtCnEqEQ.mp4",
        "question": "paint the grass and dry",
        "answer": "54.0-93.0",
        "start": null,
        "end": null,
        "duration": 148.4,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 7,
            "qcenter": 4,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/9pybtCnEqEQ.mp4",
        "question": "paint the flowers with different colors",
        "answer": "93.0-110.0",
        "start": null,
        "end": null,
        "duration": 148.4,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 7,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/9pybtCnEqEQ.mp4",
        "question": "put together flowers and grass",
        "answer": "110.0-120.0",
        "start": null,
        "end": null,
        "duration": 148.4,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/9pybtCnEqEQ.mp4",
        "question": "draw leaves",
        "answer": "120.0-125.0",
        "start": null,
        "end": null,
        "duration": 148.4,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/nN6ZOXoBjps.mp4",
        "question": "Rub off the dust and oxide ",
        "answer": "57.0-129.0",
        "start": null,
        "end": null,
        "duration": 165.47,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 5,
            "qlen": 6,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/nN6ZOXoBjps.mp4",
        "question": "Dry immediately",
        "answer": "129.0-130.0",
        "start": null,
        "end": null,
        "duration": 165.47,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/daclapuOQnE.mp4",
        "question": "take scrub and spray water",
        "answer": "73.0-82.0",
        "start": null,
        "end": null,
        "duration": 169.1,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/daclapuOQnE.mp4",
        "question": "rub out the scratches ",
        "answer": "82.0-98.0",
        "start": null,
        "end": null,
        "duration": 169.1,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/daclapuOQnE.mp4",
        "question": "use cloth to clean out",
        "answer": "98.0-114.0",
        "start": null,
        "end": null,
        "duration": 169.1,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/daclapuOQnE.mp4",
        "question": "spray water and clean with water ",
        "answer": "114.0-147.0",
        "start": null,
        "end": null,
        "duration": 169.1,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 8,
            "qcenter": 7,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/daclapuOQnE.mp4",
        "question": "use scrubber to clean it well",
        "answer": "147.0-157.0",
        "start": null,
        "end": null,
        "duration": 169.1,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/qE5eodQCqqc.mp4",
        "question": "take  metal polish into cloth",
        "answer": "22.0-38.0",
        "start": null,
        "end": null,
        "duration": 131.88,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 6,
            "qcenter": 2,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/qE5eodQCqqc.mp4",
        "question": "wiping down chrome gently ",
        "answer": "38.0-98.0",
        "start": null,
        "end": null,
        "duration": 131.88,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 6,
            "qcenter": 5,
            "qlen": 6,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/qE5eodQCqqc.mp4",
        "question": "clean by new cloth fully",
        "answer": "98.0-119.0",
        "start": null,
        "end": null,
        "duration": 131.88,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 6,
            "qcenter": 8,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/ymAgcwbWo38.mp4",
        "question": "apply liquid on parts ",
        "answer": "28.0-36.0",
        "start": null,
        "end": null,
        "duration": 66.94,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/ymAgcwbWo38.mp4",
        "question": "rub it out the dirty ",
        "answer": "36.0-40.0",
        "start": null,
        "end": null,
        "duration": 66.94,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 5,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/ymAgcwbWo38.mp4",
        "question": "use cloth to clean out",
        "answer": "40.0-47.0",
        "start": null,
        "end": null,
        "duration": 66.94,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/AEkQeihliZM.mp4",
        "question": "arrange wanted length on room",
        "answer": "29.0-44.0",
        "start": null,
        "end": null,
        "duration": 106.82,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/AEkQeihliZM.mp4",
        "question": "using spray to spread water ",
        "answer": "44.0-64.0",
        "start": null,
        "end": null,
        "duration": 106.82,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 5,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/AEkQeihliZM.mp4",
        "question": "using cloth to clean out floor",
        "answer": "64.0-87.0",
        "start": null,
        "end": null,
        "duration": 106.82,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 7,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/AEkQeihliZM.mp4",
        "question": "use machine to clean out",
        "answer": "87.0-95.0",
        "start": null,
        "end": null,
        "duration": 106.82,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 8,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/WIHPzX3zLNo.mp4",
        "question": "peel the duct tape into two",
        "answer": "53.0-67.0",
        "start": null,
        "end": null,
        "duration": 110.14,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/WIHPzX3zLNo.mp4",
        "question": "joint tape one by one",
        "answer": "67.0-73.0",
        "start": null,
        "end": null,
        "duration": 110.14,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 5,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/WIHPzX3zLNo.mp4",
        "question": "repeat the step upto make bowl",
        "answer": "73.0-99.0",
        "start": null,
        "end": null,
        "duration": 110.14,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 7,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LH6B1Ye8hYw.mp4",
        "question": "take one cup of heavy cream",
        "answer": "17.0-30.0",
        "start": null,
        "end": null,
        "duration": 110.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LH6B1Ye8hYw.mp4",
        "question": "add two TSP of buttermilk",
        "answer": "30.0-31.0",
        "start": null,
        "end": null,
        "duration": 110.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LH6B1Ye8hYw.mp4",
        "question": "wrap it with plastic cover",
        "answer": "31.0-35.0",
        "start": null,
        "end": null,
        "duration": 110.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LH6B1Ye8hYw.mp4",
        "question": "keep it room temperature for eight hours",
        "answer": "35.0-67.0",
        "start": null,
        "end": null,
        "duration": 110.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LH6B1Ye8hYw.mp4",
        "question": "transfer into other bowl",
        "answer": "67.0-70.0",
        "start": null,
        "end": null,
        "duration": 110.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LH6B1Ye8hYw.mp4",
        "question": "keep it in fridge",
        "answer": "70.0-80.0",
        "start": null,
        "end": null,
        "duration": 110.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 5,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/6C0mL9n9Nko.mp4",
        "question": "have a needed things",
        "answer": "11.0-40.0",
        "start": null,
        "end": null,
        "duration": 153.49,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/6C0mL9n9Nko.mp4",
        "question": "Using a clay design",
        "answer": "40.0-59.0",
        "start": null,
        "end": null,
        "duration": 153.49,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/6C0mL9n9Nko.mp4",
        "question": "Another clay",
        "answer": "59.0-70.0",
        "start": null,
        "end": null,
        "duration": 153.49,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 7,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/6C0mL9n9Nko.mp4",
        "question": "start pour gycerlin",
        "answer": "70.0-85.0",
        "start": null,
        "end": null,
        "duration": 153.49,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/6C0mL9n9Nko.mp4",
        "question": "Remove outer layer of clay",
        "answer": "85.0-109.0",
        "start": null,
        "end": null,
        "duration": 153.49,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/6C0mL9n9Nko.mp4",
        "question": "using chain measure the band size",
        "answer": "109.0-116.0",
        "start": null,
        "end": null,
        "duration": 153.49,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/WqVQSC5zMBw.mp4",
        "question": "put mashed potato into freezer ",
        "answer": "20.0-25.0",
        "start": null,
        "end": null,
        "duration": 38.47,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/WqVQSC5zMBw.mp4",
        "question": "using bag to store as well",
        "answer": "25.0-30.0",
        "start": null,
        "end": null,
        "duration": 38.47,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/L8kJRfPMAEY.mp4",
        "question": "Pour cereal",
        "answer": "35.0-36.0",
        "start": null,
        "end": null,
        "duration": 158.23,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/L8kJRfPMAEY.mp4",
        "question": "Add rice krispies and fruity pebbles",
        "answer": "36.0-38.0",
        "start": null,
        "end": null,
        "duration": 158.23,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/L8kJRfPMAEY.mp4",
        "question": "Add marshmallows",
        "answer": "38.0-43.0",
        "start": null,
        "end": null,
        "duration": 158.23,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/L8kJRfPMAEY.mp4",
        "question": "Mix it around",
        "answer": "43.0-47.0",
        "start": null,
        "end": null,
        "duration": 158.23,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/L8kJRfPMAEY.mp4",
        "question": "Put it in the microwave",
        "answer": "47.0-49.0",
        "start": null,
        "end": null,
        "duration": 158.23,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/L8kJRfPMAEY.mp4",
        "question": "Watch the heat",
        "answer": "49.0-71.0",
        "start": null,
        "end": null,
        "duration": 158.23,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/L8kJRfPMAEY.mp4",
        "question": "Use hot gloves to take out",
        "answer": "71.0-80.0",
        "start": null,
        "end": null,
        "duration": 158.23,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/L8kJRfPMAEY.mp4",
        "question": "Put treats in the dish",
        "answer": "80.0-82.0",
        "start": null,
        "end": null,
        "duration": 158.23,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 5,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/L8kJRfPMAEY.mp4",
        "question": "Mold the treats",
        "answer": "82.0-115.0",
        "start": null,
        "end": null,
        "duration": 158.23,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 6,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/5V3dI2zp1xA.mp4",
        "question": "add salt and water mix well",
        "answer": "20.908783721904662-44.90878372190466",
        "start": 59.09121627809534,
        "end": 159.08121627809533,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 3,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/5V3dI2zp1xA.mp4",
        "question": "heat pan and add fruit salt ",
        "answer": "42.649733380486424-59.649733380486424",
        "start": 61.350266619513576,
        "end": 141.34026661951356,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 3,
            "qcenter": 6,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/TcB42a05yzg.mp4",
        "question": "repeat until the three layer stand completed",
        "answer": "29.506170680397673-37.50617068039767",
        "start": 0.0,
        "end": 99.99,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/2YZHJOLuA8o.mp4",
        "question": "spray it and put leafs onit",
        "answer": "29.20819650945588-59.20819650945588",
        "start": 44.79180349054412,
        "end": 124.78180349054412,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 3,
            "qcenter": 5,
            "qlen": 5,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/-DiQNHSyUfs.mp4",
        "question": "slip tissue inbag and seal it",
        "answer": "32.066130904060834-48.066130904060834",
        "start": 59.933869095939166,
        "end": 139.92386909593915,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 3,
            "qcenter": 5,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/hHgiALvGm5Y.mp4",
        "question": "repeat same process on another bag",
        "answer": "48.87965173084548-64.87965173084548",
        "start": 93.12034826915452,
        "end": 193.1103482691545,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 5,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/5OVxioAu6IY.mp4",
        "question": "arrange the hardware parts",
        "answer": "37.47000912137867-56.47000912137867",
        "start": 0.0,
        "end": 99.99,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/38H8OKlNA9g.mp4",
        "question": "close the box after filling",
        "answer": "18.970610996337953-30.970610996337953",
        "start": 77.02938900366205,
        "end": 157.01938900366204,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/8KWG-HxHcbE.mp4",
        "question": "add salt and mix well",
        "answer": "20.441000887659612-38.44100088765961",
        "start": 185.5589991123404,
        "end": 325.5489991123404,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 6,
            "qcenter": 2,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/8KWG-HxHcbE.mp4",
        "question": "cook squash until fork tender",
        "answer": "41.68132733972081-69.68132733972081",
        "start": 182.3186726602792,
        "end": 282.30867266027917,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 5,
            "qlen": 4,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/8KWG-HxHcbE.mp4",
        "question": "put mixer on pot add chickenoil",
        "answer": "0.5461398841013647-18.546139884101365",
        "start": 0.0,
        "end": 99.99,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/8KWG-HxHcbE.mp4",
        "question": "add doll and mix well",
        "answer": "0.901734644380042-13.901734644380042",
        "start": 398.09826535561996,
        "end": 418.08826535561997,
        "duration": 19.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 9,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/NULTB33w3Bw.mp4",
        "question": "mix until dissolved set aside",
        "answer": "42.90107653899466-48.90107653899466",
        "start": 18.09892346100534,
        "end": 118.08892346100534,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/xcrmJR_RVIw.mp4",
        "question": "Arrange the flowers in the clutch bags",
        "answer": "10.356005999575842-89.35600599957584",
        "start": 20.643994000424158,
        "end": 160.63399400042417,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 6,
            "qcenter": 3,
            "qlen": 8,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/lpyvvneQImU.mp4",
        "question": "Reduce heat and simmer until thickened",
        "answer": "12.048079966945295-38.048079966945295",
        "start": 138.9519200330547,
        "end": 218.9419200330547,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 4,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/9Bc1mU0LMF8.mp4",
        "question": "Fold it and iron",
        "answer": "18.916068065922673-41.91606806592267",
        "start": 0.0,
        "end": 99.99,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 3,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/UK3-ZpnogDc.mp4",
        "question": "Repeat the process",
        "answer": "6.565390692082929-97.56539069208293",
        "start": 170.43460930791707,
        "end": 310.4246093079171,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 6,
            "qcenter": 3,
            "qlen": 9,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/pzvKbNsG-T8.mp4",
        "question": "put message on paper and send",
        "answer": "9.88817001494374-35.88817001494374",
        "start": 290.11182998505626,
        "end": 370.10182998505627,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 3,
            "qcenter": 2,
            "qlen": 4,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/oDRoXgINJAU.mp4",
        "question": "boil water and add meat on ",
        "answer": "4.268665576397609-17.26866557639761",
        "start": 103.73133442360239,
        "end": 123.72133442360239,
        "duration": 19.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 0,
            "qcenter": 5,
            "qlen": 9,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/qPzWyc-XTQ4.mp4",
        "question": "Keep doing the process",
        "answer": "40.749004378743216-71.74900437874322",
        "start": 0.2509956212567843,
        "end": 100.24099562125679,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 5,
            "qlen": 4,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/qPzWyc-XTQ4.mp4",
        "question": "Repeat the process",
        "answer": "14.026324045849208-117.02632404584921",
        "start": 118.97367595415079,
        "end": 278.9636759541508,
        "duration": 159.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 7,
            "qcenter": 4,
            "qlen": 9,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/PiIfYPwuw7c.mp4",
        "question": "Cut and fold the tape",
        "answer": "41.1969501299547-56.1969501299547",
        "start": 168.8030498700453,
        "end": 248.7930498700453,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 3,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/8_Mg-mOvvMw.mp4",
        "question": "spray oil , salt and bake",
        "answer": "38.43970057053565-53.43970057053565",
        "start": 41.56029942946435,
        "end": 181.55029942946436,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 6,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/8_Mg-mOvvMw.mp4",
        "question": "cut beetroot and garlic",
        "answer": "9.993266488679879-10.993266488679879",
        "start": 85.00673351132012,
        "end": 104.99673351132012,
        "duration": 19.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 0,
            "qcenter": 5,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/8_Mg-mOvvMw.mp4",
        "question": "add canon oil,salt and mash it",
        "answer": "2.6571804734002598-10.65718047340026",
        "start": 104.34281952659974,
        "end": 124.33281952659974,
        "duration": 19.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 6,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/8_Mg-mOvvMw.mp4",
        "question": "cut the bread into slices and toast",
        "answer": "23.845725414994007-64.845725414994",
        "start": 0.0,
        "end": 99.99,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 6,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/e76KWpbPdfY.mp4",
        "question": "Turn key over and push",
        "answer": "8.770818412169433-15.770818412169433",
        "start": 449.22918158783057,
        "end": 469.2191815878306,
        "duration": 19.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 0,
            "qcenter": 6,
            "qlen": 5,
            "dataset": "hirest",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/TcB42a05yzg.mp4",
        "question": "color all with color spray",
        "answer": "25.183211152789635-32.18321115278964",
        "start": 18.816788847210365,
        "end": 98.80678884721036,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/TcB42a05yzg.mp4",
        "question": "change the candlestick size to our need",
        "answer": "46.292862350994966-95.29286235099497",
        "start": 37.707137649005034,
        "end": 177.69713764900504,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 6,
            "qcenter": 5,
            "qlen": 5,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/38H8OKlNA9g.mp4",
        "question": "check the temperature between the correct degree",
        "answer": "63.58380168514779-91.58380168514779",
        "start": 86.41619831485221,
        "end": 226.40619831485222,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 6,
            "qcenter": 5,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/qnN_OLNAHvc.mp4",
        "question": "Check the depth",
        "answer": "55.80945348698157-68.80945348698157",
        "start": 140.19054651301843,
        "end": 240.18054651301844,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 4,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/5JpT5RcuFUk.mp4",
        "question": "Get plastic glass table",
        "answer": "8.92897222321622-10.92897222321622",
        "start": 106.07102777678378,
        "end": 126.06102777678377,
        "duration": 19.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/pzvKbNsG-T8.mp4",
        "question": "pain color on flowers",
        "answer": "11.822236948859967-28.822236948859967",
        "start": 235.17776305114003,
        "end": 315.16776305114,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LFufa6Nfc6Y.mp4",
        "question": "snow look so good ",
        "answer": "65.46797513597699-69.46797513597699",
        "start": 2.5320248640230147,
        "end": 142.52202486402302,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 6,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LFufa6Nfc6Y.mp4",
        "question": "all can be yummy ",
        "answer": "42.959149844274194-62.959149844274194",
        "start": 89.0408501557258,
        "end": 229.03085015572583,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 6,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/ZROZTtnz2Jc.mp4",
        "question": "design toys with colorful cookies",
        "answer": "28.928220957172726-50.92822095717273",
        "start": 0.0,
        "end": 99.99,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 4,
            "qcenter": 3,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/ZROZTtnz2Jc.mp4",
        "question": "dip mash mellow with chocolate",
        "answer": "40.22047930904779-60.22047930904779",
        "start": 136.7795206909522,
        "end": 236.76952069095222,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 4,
            "qcenter": 5,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/n_h7GGgUhDM.mp4",
        "question": "select a container with drainage ",
        "answer": "0.007376774549086917-12.007376774549087",
        "start": 92.99262322545091,
        "end": 112.98262322545091,
        "duration": 19.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 9,
            "dataset": "hirest",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/FcRrnEpE4x8.mp4",
        "question": "Do over print",
        "answer": "6.67234295765428-16.67234295765428",
        "start": 321.3276570423457,
        "end": 341.31765704234573,
        "duration": 19.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 0,
            "qcenter": 5,
            "qlen": 7,
            "dataset": "hirest",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/-DiQNHSyUfs.mp4",
        "question": "shut the bag but corner open",
        "answer": "40.46864522819569-60.46864522819569",
        "start": 11.53135477180431,
        "end": 91.52135477180431,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 3,
            "qcenter": 6,
            "qlen": 3,
            "dataset": "hirest",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/HjEf_JHzqe8.mp4",
        "question": "Check condenser",
        "answer": "38.75848866391094-40.75848866391094",
        "start": 7.2415113360890615,
        "end": 147.23151133608906,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 6,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/38H8OKlNA9g.mp4",
        "question": "check the filling status of charcoal",
        "answer": "73.33441598009733-74.33441598009733",
        "start": 11.665584019902667,
        "end": 151.65558401990268,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 6,
            "qcenter": 5,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/38H8OKlNA9g.mp4",
        "question": "ensure air can get around the wood",
        "answer": "86.11940701425144-93.11940701425144",
        "start": 21.880592985748564,
        "end": 161.87059298574857,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/qnN_OLNAHvc.mp4",
        "question": "Keep cords dry",
        "answer": "68.24663958911526-75.24663958911526",
        "start": 154.75336041088474,
        "end": 294.74336041088475,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 6,
            "qcenter": 5,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/NULTB33w3Bw.mp4",
        "question": "mix and get right consistency ",
        "answer": "33.3925020056011-66.3925020056011",
        "start": 0.0,
        "end": 99.99,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/qnN_OLNAHvc.mp4",
        "question": "Spray water on blade while cutting",
        "answer": "23.91717522695592-37.91717522695592",
        "start": 185.08282477304408,
        "end": 265.0728247730441,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/WcyDbvsftkI.mp4",
        "question": "Paste all the pieces through the pattern",
        "answer": "54.83591524666261-77.83591524666261",
        "start": 183.1640847533374,
        "end": 323.15408475333743,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LFufa6Nfc6Y.mp4",
        "question": "arrange all jelly into show ",
        "answer": "19.63461043414972-34.63461043414972",
        "start": 97.36538956585028,
        "end": 177.35538956585026,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/iKRdPAsOPPk.mp4",
        "question": "use three different colors to stick",
        "answer": "1.5595335004620452-9.559533500462045",
        "start": 22.440466499537955,
        "end": 42.43046649953796,
        "duration": 19.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 0,
            "qcenter": 2,
            "qlen": 6,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/94Kea14_1I0.mp4",
        "question": "Mark and put lines on paper",
        "answer": "40.67579131455445-50.67579131455445",
        "start": 17.324208685445548,
        "end": 157.31420868544555,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/yWpSs787IRI.mp4",
        "question": "stich elastic using threads and pins ",
        "answer": "45.76032047229225-73.76032047229225",
        "start": 75.23967952770775,
        "end": 175.22967952770773,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 5,
            "qlen": 4,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/Dz_BZ48BhsA.mp4",
        "question": "Adjust and cut it",
        "answer": "27.654357691011285-56.654357691011285",
        "start": 0.0,
        "end": 99.99,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/IX86Gre7d2Y.mp4",
        "question": "Make dart and stitch",
        "answer": "2.199826568292252-23.199826568292252",
        "start": 73.80017343170775,
        "end": 213.79017343170776,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/8_Mg-mOvvMw.mp4",
        "question": "assemble everything with omelette",
        "answer": "94.86556614824565-109.86556614824565",
        "start": 81.13443385175435,
        "end": 221.12443385175436,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 7,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/vxDNQjk75dU.mp4",
        "question": "Make a cookie dough",
        "answer": "45.763901122305555-50.763901122305555",
        "start": 101.23609887769445,
        "end": 201.22609887769443,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/e76KWpbPdfY.mp4",
        "question": "Do both same time",
        "answer": "39.465851167913314-48.465851167913314",
        "start": 0.0,
        "end": 99.99,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LFufa6Nfc6Y.mp4",
        "question": "fourteen desert are there ",
        "answer": "42.4548802481746-57.4548802481746",
        "start": 29.545119751825403,
        "end": 129.5351197518254,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "hirest",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/LFufa6Nfc6Y.mp4",
        "question": "set seven topping here ",
        "answer": "4.686925976382312-16.686925976382312",
        "start": 92.31307402361769,
        "end": 112.30307402361768,
        "duration": 19.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 0,
            "qcenter": 5,
            "qlen": 9,
            "dataset": "hirest",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/IX86Gre7d2Y.mp4",
        "question": "locate the seams",
        "answer": "4.425718125458104-12.425718125458104",
        "start": 0.0,
        "end": 99.99,
        "duration": 99.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "hirest",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/IX86Gre7d2Y.mp4",
        "question": "Do back for no side seam",
        "answer": "33.05810817863459-34.05810817863459",
        "start": 41.94189182136541,
        "end": 121.93189182136541,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 3,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "hirest",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/VideoMind-Dataset/hirest/videos/e76KWpbPdfY.mp4",
        "question": "Feel vertical bars",
        "answer": "18.663198993811292-52.66319899381129",
        "start": 124.33680100618871,
        "end": 204.3268010061887,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/hirest_formated_moment_evaluation_gt.json",
        "dataset_name": "hirest",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 3,
            "qcenter": 4,
            "qlen": 6,
            "dataset": "hirest",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "continue cutting slicing the onion pieces completely across from end to end",
        "answer": "55.65-67.69",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 7,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He puts the spoon in the sink and gathers up the egg shells to put them in the trash.",
        "answer": "138.3-148.23",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The man moves the chopped herbs onto a plate.",
        "answer": "66.5-87.24",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 7,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The man cuts the bread.",
        "answer": "32.93-44.35",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person takes a chopping board out of the drawer.",
        "answer": "6.02-9.76",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person gets a small plate from the cupboard.",
        "answer": "62.52-77.52",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "The person peels the onion and cuts it in half.",
        "answer": "25.75-60.78",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 7,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "Person takes out bread.",
        "answer": "6.22-16.19",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "The person procures a plate from the cabinet.",
        "answer": "100.65-110.31",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person gathers herbs from a container and brings them over to the cutting board.",
        "answer": "17.18-32.86",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He uses the spoon to put the egg yolk into the other bowl.",
        "answer": "131.39-136.39",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person chops up the herbs.",
        "answer": "33.2-61.73",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person grabs a small spoon.",
        "answer": "31.77-40.61",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "Find a plate or dish of appropriate size.",
        "answer": "60.07-77.52",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He smacks the shell with the spoon and removes a tiny piece of shell.",
        "answer": "38.16-55.44",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 8,
            "qcenter": 2,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The person takes out a cutting board.",
        "answer": "16.6-21.97",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "Person puts cutting board on counter",
        "answer": "16.6-20.27",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "Person cuts a half inch piece from top of loaf down to cutting board.",
        "answer": "32.93-44.35",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "place diced onion on a plate and season with lemon juice",
        "answer": "120.24-144.32",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 7,
            "qcenter": 8,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He pours the whites into one dish.",
        "answer": "86.5-108.67",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "Next, he places fresh herbs on the cutting board.",
        "answer": "17.18-32.86",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "He cut the Onion in half and finished the peeling process",
        "answer": "39.83-54.76",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 7,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person makes a hole in the eggshell with the spoon.",
        "answer": "38.16-72.86",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person retrieves another plate.",
        "answer": "36.84-48.54",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "Placed the empty shell on the plate and arranged the cups.",
        "answer": "97.93-112.07",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 8,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "Get two bowls, an egg, and a spoon.",
        "answer": "6.33-36.87",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He goes to the cupboard and takes out two bowls.",
        "answer": "6.33-12.18",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "He dices the first half of the onion.",
        "answer": "61.73-73.57",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The person uses the knife to slice a piece of bread from the loaf.",
        "answer": "32.93-44.35",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "He peeled onion",
        "answer": "31.46-37.65",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "She make the egg hole bigger and puts the yolk in the other cup.",
        "answer": "106.8-116.39",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "Pour the egg white out of the small hole created before, into one of the bowls.",
        "answer": "86.5-108.67",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "The man got out a cutting board.",
        "answer": "13.47-18.06",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "Place fresh herbs on to cutting board.",
        "answer": "17.18-36.19",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "He walked to the back cabinets and took out an onion.",
        "answer": "5.61-12.35",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 7,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The man takes a large knife out of a drawer.",
        "answer": "22.21-27.45",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "the person slices the bread",
        "answer": "32.93-44.35",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person scoops out the yolk with the spoon and puts it in the second bowl.",
        "answer": "131.39-136.39",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "The person gets out a knife.",
        "answer": "18.5-23.33",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person gets out an egg cup.",
        "answer": "24.52-31.53",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person gets out an egg cup.",
        "answer": "31.77-36.16",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "The man cuts the ends off the onion.",
        "answer": "25.75-29.8",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He made small hole in egg",
        "answer": "38.16-55.44",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 2,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "Cleared the cutting board.",
        "answer": "55.65-60.78",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 7,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person takes some herb stalks from a plant on the counter.",
        "answer": "17.18-32.86",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "Person closes refrigerator door.",
        "answer": "6.22-16.19",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He makes a small hole in the egg.",
        "answer": "59.42-77.35",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person cleans up by throwing out the egg shell, then washing his spoon and hands.",
        "answer": "144.8-170.0",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person gets out a spoon.",
        "answer": "36.84-40.61",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "Person cuts one slice of bread from loaf.",
        "answer": "32.93-44.35",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The person unwraps the bread.",
        "answer": "27.82-31.84",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person washes and puts away the spoon.",
        "answer": "144.8-164.42",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "He took out cutting board",
        "answer": "13.47-18.06",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person breaks the egg open wider and pours more egg white into the first bowl.",
        "answer": "111.16-131.39",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "the person gets a cutting board",
        "answer": "16.6-20.27",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person got out two bowls.",
        "answer": "6.33-12.18",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The man places the loaf of bread on the cutting board.",
        "answer": "27.82-31.84",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He spoon out the whole, central yolk into another bowl.",
        "answer": "122.76-140.34",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 7,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person pours the egg whites into one of the cups.",
        "answer": "59.15-106.56",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 7,
            "qlen": 6,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person procures some sprigs of herbs from the countertop off screen.",
        "answer": "17.18-32.86",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He washes his hands and the spoon, puts the spoon away, brushes off some egg shells, and wets his hands again.",
        "answer": "164.66-170.0",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "person gets 2 small cups",
        "answer": "16.84-22.99",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person finds a spoon from the drawer.",
        "answer": "24.63-36.87",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "Squeeze lemon juice onto the diced onion.",
        "answer": "100.65-144.32",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person completely drains the egg white.",
        "answer": "59.15-106.56",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 7,
            "qlen": 6,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "The person puts the onion pieces on the plate.",
        "answer": "112.65-117.86",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person drains the egg white through the hole in the shell onto a plate.",
        "answer": "86.5-108.67",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He opens the egg more and pours the yolk into the other dish.",
        "answer": "111.16-136.39",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person got out an egg.",
        "answer": "13.64-23.54",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "She took out a spoon",
        "answer": "24.52-36.16",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "He took out cutting board",
        "answer": "16.6-20.27",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He shakes the egg to make the insides drip into one of the bowls.",
        "answer": "72.86-108.67",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 8,
            "qcenter": 5,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person gets out some herbs.",
        "answer": "17.18-32.86",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He washes the spoon and puts it away in the drawer.",
        "answer": "156.63-164.42",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "Person puts down loaf of bread on counter.",
        "answer": "6.22-16.19",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "He gets a knife.",
        "answer": "22.21-27.45",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "He slices off one slice of bread.",
        "answer": "32.93-44.35",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He takes out two small bowls.",
        "answer": "6.33-12.18",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person takes out a small plate and places it on the counter.",
        "answer": "49.8-58.57",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person takes an egg out of the fridge.",
        "answer": "6.97-22.99",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 1,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The person takes out a knife from the drawer.",
        "answer": "20.51-27.45",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "he cover a portion of the onion with the lemon juice.",
        "answer": "139.42-144.32",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The man opens the fridge",
        "answer": "6.22-16.19",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person lightly shakes out the excess liquid from the egg into the first bowl using the newly created hole.",
        "answer": "72.86-108.67",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 8,
            "qcenter": 5,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "She drained yolk from egg",
        "answer": "59.15-97.11",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 6,
            "qlen": 4,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "He stood over bread",
        "answer": "27.82-44.35",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 2,
            "qcenter": 7,
            "qlen": 5,
            "dataset": "tacos",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "Got a spoon and tapped the egg on top to break the shell.",
        "answer": "31.77-40.61",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "She put hole in egg",
        "answer": "49.8-58.57",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "He gets the loaf of bread out of the fridge.",
        "answer": "6.22-16.19",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person chopped the herbs",
        "answer": "36.6-63.78",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person gets out two bowls.",
        "answer": "6.33-12.18",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "Held the egg over the plate and peeled a larger hole in the egg shell and poured the egg yolk into a cup.",
        "answer": "97.93-108.13",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 8,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person puts the spoon in the sink and throws the shells into the wastebin.",
        "answer": "138.3-148.23",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "He took out plate",
        "answer": "100.65-110.31",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "Person puts knife down.",
        "answer": "32.93-44.35",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "Poured the egg white from the shell into a cup.",
        "answer": "59.15-97.11",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 6,
            "qlen": 4,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person rinses the knife.",
        "answer": "88.88-93.44",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He turns on the sink and washes his hands.",
        "answer": "148.67-150.71",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "Wash and dry knife",
        "answer": "88.88-96.6",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person procures some fresh herbs from a plant out of frame.",
        "answer": "17.18-32.86",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "Person pulls out loaf of bread.",
        "answer": "6.22-16.19",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "He gets the cutting board out of the cupboard.",
        "answer": "16.6-20.27",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "The person adds lemon juice to the onion.",
        "answer": "139.42-144.32",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person wipes the knife dry with a cloth.",
        "answer": "92.65-96.6",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "Person takes out knife.",
        "answer": "20.51-27.45",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The person cuts off a slice of bread.",
        "answer": "32.93-44.35",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The person holds the bread firmly in his left hand.",
        "answer": "27.82-31.84",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "Crack a larger hole in the egg shell, and scoop the yolk out.",
        "answer": "111.16-136.39",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He uses his fingers and the spoon to make the hole bigger.",
        "answer": "56.39-72.86",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 8,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person scoops the yolk out with the spoon and puts it in the second bowl.",
        "answer": "131.39-136.39",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person gets out a spoon.",
        "answer": "24.63-36.87",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "She gets two cups.",
        "answer": "24.52-31.53",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The man takes bread out of the fridge.",
        "answer": "6.22-16.19",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "The person chops the onion in half and peels it further.",
        "answer": "39.83-54.76",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 7,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The man sets the bread aside on the cutting board.",
        "answer": "32.93-44.35",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "Take out an onion, knife, and cutting board. Place the cutting board on the counter and place the onion on the cutting board.",
        "answer": "5.61-23.33",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 7,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "Man cuts vegetables in half.",
        "answer": "33.2-39.22",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person puts both piles of herbs together and uses the knife to line them up evenly.",
        "answer": "39.22-41.12",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He takes two bowls from the cupboard.",
        "answer": "6.33-12.18",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person washes and dries the knife.",
        "answer": "92.65-96.02",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person uses the spoon to scoop out the yoke from the egg, and places it into the second bowl.",
        "answer": "131.39-136.39",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person cleaned up the egg shell.",
        "answer": "138.3-148.23",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "He put herbs in plate",
        "answer": "78.16-87.24",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 8,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person removes a large knife from the drawer.",
        "answer": "9.9-14.29",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person put herbs on the cutting board.",
        "answer": "17.18-36.19",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "He gets a loaf of bread.",
        "answer": "6.22-16.19",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person moves both cups to the center of the table.",
        "answer": "112.93-116.39",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He takes a spoon from the drawer.",
        "answer": "24.63-36.87",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "She further enlarges the hole with her fingers.",
        "answer": "112.93-116.39",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He uses his fingers and the spoon to build a bigger hole in the shell.",
        "answer": "56.39-77.35",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 8,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person procures a plate from the cabinet.",
        "answer": "66.5-77.52",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 7,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "Person takes out cutting board.",
        "answer": "16.6-20.27",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The person carefully carves a half inch slice of bread from the end of the loaf.",
        "answer": "32.93-44.35",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person cleaned up.",
        "answer": "164.66-170.0",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "the person unwraps the bread",
        "answer": "27.82-31.84",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The person removes the loaf of bread from its wrapper.",
        "answer": "27.82-31.84",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person procures an egg from the fridge.",
        "answer": "13.64-23.54",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person washes his hands.",
        "answer": "138.3-161.46",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person breaks the shell open with his fingers and scoops the egg yolk out onto the second plate with the spoon.",
        "answer": "111.16-136.39",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The person takes out a cutting board from the drawer.",
        "answer": "16.6-20.27",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person gets an egg from the fridge.",
        "answer": "13.64-23.54",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "Dice the rest of the onions into square bits.",
        "answer": "61.73-88.71",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 5,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The man takes a cutting board out of a drawer.",
        "answer": "16.6-21.97",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "He takes out the loaf.",
        "answer": "27.82-31.84",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person takes two cups from the cabinet and puts them on the table.",
        "answer": "16.84-22.99",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "Make sure none of the egg shell got into your eggs.",
        "answer": "152.93-156.26",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He begins washing his hands, throws away a piece of shell he sees in the bowl of egg whites, washes his hands some more, and washes the spoon and puts it away.",
        "answer": "148.67-164.42",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "The person gets out a plate.",
        "answer": "42.28-58.57",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person clears out the hole of excess shell using his fingers, and the spoon.",
        "answer": "47.14-72.86",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person washes the knife in the sink.",
        "answer": "88.88-91.46",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "She removes a bit more of the shell and pours the yolk into the other glass.",
        "answer": "106.8-112.07",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person opened a drawer",
        "answer": "6.02-9.76",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "The man takes out an onion, a cutting board, and a knife.",
        "answer": "5.61-23.33",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "slice the onion directly in half and peel away any excess skin from each half",
        "answer": "39.83-54.76",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 7,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He took out egg",
        "answer": "13.64-23.54",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person lightly taps the top of the egg with the spoon until a little hole appears.",
        "answer": "38.16-47.14",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person pours egg white through the hole into one bowl.",
        "answer": "72.86-108.67",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 5,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person grabs an egg from the refrigerator, and walks back to the bowls.",
        "answer": "13.64-23.54",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The person procures a loaf of bread from the fridge.",
        "answer": "6.22-16.19",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He takes an egg from the refrigerator.",
        "answer": "13.64-23.54",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person gathers the egg shell fragments, throws them away, and then washes his hands in the sink.",
        "answer": "148.67-161.46",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "He gets out an egg from the refrigerator.",
        "answer": "13.64-23.54",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s33-d50.avi",
        "question": "person gently taps top of the egg to crack the top only",
        "answer": "36.84-40.61",
        "start": null,
        "end": null,
        "duration": 117.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "person unwraps load of bread.",
        "answer": "27.82-31.84",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d29.avi",
        "question": "The person uses the knife to scoop up the herbs and places them onto the small plate.",
        "answer": "78.16-87.24",
        "start": null,
        "end": null,
        "duration": 101.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 5,
            "qcenter": 8,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d50.avi",
        "question": "The person got out a spoon.",
        "answer": "24.63-36.87",
        "start": null,
        "end": null,
        "duration": 176.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s37-d25.avi",
        "question": "The man gets the bread out of the refrigerator.",
        "answer": "6.22-16.19",
        "start": null,
        "end": null,
        "duration": 48.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "tacos",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/TACoS/videos/s36-d27.avi",
        "question": "cut onion in half and peel remaining skin",
        "answer": "39.83-54.76",
        "start": null,
        "end": null,
        "duration": 148.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/tacos_val.json",
        "dataset_name": "tacos",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 7,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "tacos",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_8wB0BOjuyes.mp4",
        "question": "The horses all go running and the man once again reaches down and hits the ball with his stick and they all continue to ride on their running horses.",
        "answer": "6.9-16.23",
        "start": null,
        "end": null,
        "duration": 16.23,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 0,
            "qcenter": 7,
            "qlen": 8,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_5QbiJmDyoM0.mp4",
        "question": " She does several flips and springs across the beam.",
        "answer": "12.7-57.64",
        "start": 0.0,
        "end": 97.69,
        "duration": 97.69,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 3,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_dcEdjqyHj8M.mp4",
        "question": "Two men are seen chainsawing on a stage while a man stands in the middle.",
        "answer": "0.0-13.13",
        "start": null,
        "end": null,
        "duration": 62.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_Aygp8JaMkqQ.mp4",
        "question": " Large waves in the water appear with people trying to body surf them, mostly unsuccessfully.",
        "answer": "56.83-157.36",
        "start": null,
        "end": null,
        "duration": 174.85,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 8,
            "qcenter": 6,
            "qlen": 8,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_6skP3w9WDIM.mp4",
        "question": " More clips are shown of them wrapping.",
        "answer": "63.22-92.43",
        "start": null,
        "end": null,
        "duration": 95.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_BioBrxuKOsw.mp4",
        "question": " They are involved in a game of polo.",
        "answer": "12.32-46.21",
        "start": null,
        "end": null,
        "duration": 68.45,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 4,
            "qlen": 7,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_bWdufJDosIo.mp4",
        "question": "a woman holding rolls of wall paper starts talking to the camera.",
        "answer": "0.0-15.74",
        "start": null,
        "end": null,
        "duration": 121.05,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_AUPs7Ukfc1I.mp4",
        "question": " He continues shaving his chin and stops to look at the camera.",
        "answer": "87.25-132.92",
        "start": null,
        "end": null,
        "duration": 136.33,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 8,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_WTfeKnRJ17g.mp4",
        "question": " They continue dancing around and performing with the jump ropes.",
        "answer": "61.91-90.8",
        "start": null,
        "end": null,
        "duration": 91.72,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_mbGpp_nDwI4.mp4",
        "question": " He caught his feet with the bars, he stop and reach for the powder and another man approach him.",
        "answer": "52.04-68.25",
        "start": null,
        "end": null,
        "duration": 98.2,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_94q8YdJoPUw.mp4",
        "question": "After several subtitles,a man appears kayaking just sitting in the middle of the current struggling to go forward.",
        "answer": "32.98-66.86",
        "start": null,
        "end": null,
        "duration": 89.14,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 5,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_0YHCiC7IIg8.mp4",
        "question": " There is also an orchestra playing various instruments with a conductor directing them.",
        "answer": "126.16-128.08",
        "start": null,
        "end": null,
        "duration": 128.08,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_smh90DBXsBg.mp4",
        "question": "  A woman is shown sitting in a chair and receiving a tattoo by a tattooed tattoo artist wearing white gloves and a backwards baseball cap.",
        "answer": "0.0-25.19",
        "start": null,
        "end": null,
        "duration": 129.2,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_mkEME_iWi9o.mp4",
        "question": " They run after the ball and hit it toward the goal.",
        "answer": "69.45-88.47",
        "start": null,
        "end": null,
        "duration": 88.47,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_4cqesj6HwTU.mkv",
        "question": " She then talks about the beer and serving it.",
        "answer": "59.02-75.66",
        "start": null,
        "end": null,
        "duration": 75.66,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_uDlyfvy0NOs.mp4",
        "question": " He then shows how the cookie dough begins melting and even baking in the heat of the sunlight.",
        "answer": "8.41285778418392-36.072857784183924",
        "start": 0.0,
        "end": 80.18,
        "duration": 80.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 2,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_SrcZRhXkr2k.mp4",
        "question": "The man reaches his hand out, shakes the woman's hand, and gives her a side hug while they both walk towards the door to exit the room.",
        "answer": "80.01-89.9",
        "start": null,
        "end": null,
        "duration": 94.13,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_sPSfixKrDc0.mp4",
        "question": "The man is back at the large light gray counter and in a sped up motion the man is shown with various different supplies as he assembles a very large truck cake that was previously shown.",
        "answer": "26.16-96.77",
        "start": null,
        "end": null,
        "duration": 130.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 4,
            "qlen": 8,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_IiCN1md2MV4.mp4",
        "question": " Then, the man on back hit the ball that comes on the back.",
        "answer": "3.84-7.44",
        "start": null,
        "end": null,
        "duration": 12.19,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_lI6h3H4Zs98.mp4",
        "question": "  A group of young people perform sophisticated jump rope tricks in a gym.",
        "answer": "6.4-46.65",
        "start": 0.0,
        "end": 91.46,
        "duration": 91.46,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 2,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_PUWg7fXnCf0.mkv",
        "question": " A woman is jump roping on a street and doing flips.",
        "answer": "48.06-48.73",
        "start": null,
        "end": null,
        "duration": 133.51,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_Ofnuo7FTHfM.mp4",
        "question": " They both climb up different ladders.",
        "answer": "2.46-6.18",
        "start": null,
        "end": null,
        "duration": 10.47,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_AJ_a4fE-rR0.mp4",
        "question": "A surfer rides over an ocean wave multiple times.",
        "answer": "0.0-17.55",
        "start": null,
        "end": null,
        "duration": 121.05,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_2TEJnQzCPUM.mp4",
        "question": " The video ends with the closing credits shown at the end of the video.",
        "answer": "69.18-72.82",
        "start": null,
        "end": null,
        "duration": 72.82,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 3,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_kWtY5wkkAMY.mp4",
        "question": " The screen goes black and we see the ending title screen and website address.",
        "answer": "51.95-56.77",
        "start": null,
        "end": null,
        "duration": 56.77,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 2,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_O5vpeIfQxLQ.mp4",
        "question": "A collage of still photos shows people eating.",
        "answer": "0.0-6.35",
        "start": null,
        "end": null,
        "duration": 158.73,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 7,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_y9bLCC26MGQ.mp4",
        "question": " His jump is shown again in slow motion.",
        "answer": "26.0-36.14",
        "start": null,
        "end": null,
        "duration": 36.87,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 1,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_QKEFacWrn_8.mp4",
        "question": "  A blue screen appears and a red, white and blue logo with a W on it appears.",
        "answer": "129.16-130.5",
        "start": null,
        "end": null,
        "duration": 134.54,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 6,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_6WQSZekz8vQ.mp4",
        "question": " We see the closing ending credits.",
        "answer": "49.97-56.15",
        "start": null,
        "end": null,
        "duration": 56.15,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 2,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_URgF15eyQvg.mp4",
        "question": " At the end, the four man are shown again and then the logo of the show, and finally a website address is shown.",
        "answer": "117.49-130.84",
        "start": null,
        "end": null,
        "duration": 133.52,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 6,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_v34qczSoYLo.mp4",
        "question": " Then we see it from a far away perspective camera and the logo is shown again with the website.",
        "answer": "10.20585956399374-36.545859563993744",
        "start": 0.0,
        "end": 95.78,
        "duration": 95.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 4,
            "qcenter": 2,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_o67-Z8n-jEE.mp4",
        "question": " The logo returns with terms and conditions.",
        "answer": "166.41-177.03",
        "start": null,
        "end": null,
        "duration": 177.03,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 8,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_6g80a1NnftU.mp4",
        "question": "A person is washing their hands as the words \"Tutorial: How to Wash Your Hands\" appears on screen.",
        "answer": "0.0-2.57",
        "start": null,
        "end": null,
        "duration": 128.43,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_z0tiCqKa4cs.mp4",
        "question": " All of a sudden, a jar of Mayonnaise,a loaf of bread,and a tomato appears.",
        "answer": "19.94-52.86",
        "start": null,
        "end": null,
        "duration": 92.74,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 4,
            "qcenter": 3,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_Y7VWbYGI0Oc.mp4",
        "question": " We see bright spots fly about on the lens of the camera.",
        "answer": "8.02-10.44",
        "start": null,
        "end": null,
        "duration": 24.29,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 1,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_AMMECm7Huhk.mp4",
        "question": " When the video is over the closing credits and graphics are shown on the screen.",
        "answer": "149.28-166.79",
        "start": null,
        "end": null,
        "duration": 166.79,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 8,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_eYgXvnnlPQA.mp4",
        "question": "An introduction comes onto the screen for a video about rock climbing and a man introduces what will happen in the video.",
        "answer": "0.0-16.21",
        "start": null,
        "end": null,
        "duration": 140.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 7,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_fxgbk_Kk4Rw.mp4",
        "question": " The two vacuum cleaners are shown once again side by side with text showcasing their features.",
        "answer": "96.26-114.5",
        "start": null,
        "end": null,
        "duration": 125.83,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 6,
            "qcenter": 8,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_OwchMqCYaF4.mp4",
        "question": " The video continues with more clips of people falling down.",
        "answer": "91.45-163.42",
        "start": null,
        "end": null,
        "duration": 169.34,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 8,
            "qcenter": 7,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_rKtktLDSOpA.mp4",
        "question": "The camera is blurry then focuses on people playing polo.",
        "answer": "0.0-23.78",
        "start": null,
        "end": null,
        "duration": 128.52,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_aS0wGPhD48o.mp4",
        "question": "A woman's vibrantly painted fingernails are shown on screen with the word \"superWOWstyle!\" shown.",
        "answer": "0.0-6.8",
        "start": null,
        "end": null,
        "duration": 80.04,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ay_YB-S4qR0.mp4",
        "question": " More darts are seen moving into frame.",
        "answer": "23.54-34.27",
        "start": null,
        "end": null,
        "duration": 34.62,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 1,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_DP9hfhq8sro.mp4",
        "question": " The camera then pans all around a fooseball table.",
        "answer": "3.74-12.63",
        "start": null,
        "end": null,
        "duration": 18.72,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 7,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_JE0xYYOp5_s.mp4",
        "question": " The lady speak to the camera and we see the closing screen.",
        "answer": "64.86-82.11",
        "start": null,
        "end": null,
        "duration": 82.11,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 4,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_AY6QSTuHGRc.mp4",
        "question": "From behind a black screen a go pro camera emerges into view followed by the logo.",
        "answer": "0.0-16.85",
        "start": null,
        "end": null,
        "duration": 168.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_jd609r5yKkI.mp4",
        "question": " When the video in the closing captions and credits are shown on the screen.",
        "answer": "131.49-143.71",
        "start": null,
        "end": null,
        "duration": 143.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment Change",
        "bins": {
            "videolen": 7,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "EC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_DfOiHMcrCbs.mp4",
        "question": " Several packs of cigarettes are shown with more people smoking.",
        "answer": "9.056039414047069-50.06603941404707",
        "start": 5.973960585952931,
        "end": 65.96396058595292,
        "duration": 59.989999999999995,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 7,
            "dataset": "anet",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_aWnpbk007cE.mp4",
        "question": "There are a couple of kites in the sky above a green field with a few people scattered.",
        "answer": "0.0-3.73",
        "start": null,
        "end": null,
        "duration": 82.85,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_sPSfixKrDc0.mp4",
        "question": "A large truck cake is shown, a smaller one next to it, and the toy truck is also there.",
        "answer": "18.31-26.16",
        "start": null,
        "end": null,
        "duration": 130.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 6,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ANwaFSIHdW0.mp4",
        "question": " There are three dogs following her around the playground.",
        "answer": "5.62-26.93",
        "start": null,
        "end": null,
        "duration": 38.76,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 1,
            "qcenter": 4,
            "qlen": 8,
            "dataset": "anet",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v__uOfIm1tFcI.mp4",
        "question": " The boy is then seen flipping on bounce tarps outdoors before returning to flipping on grass.",
        "answer": "56.1-125.55",
        "start": null,
        "end": null,
        "duration": 133.56,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 7,
            "dataset": "anet",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_sODu6d-3zAQ.mp4",
        "question": " After that she talks for a bit more and then spins it on her hips for a while again.",
        "answer": "3.3544358736289794-49.20443587362898",
        "start": 40.68556412637102,
        "end": 100.67556412637101,
        "duration": 59.989999999999995,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 4,
            "qcenter": 7,
            "qlen": 7,
            "dataset": "anet",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_B5Ea3Bs8hC4.mp4",
        "question": " The man goes back to the pink bucket to wash another dark item clothing, he wrings it out in the pink bucket, throws it in the yellow bucket, then wrings his hands together a few times while staring at the camera.",
        "answer": "33.08-73.52",
        "start": null,
        "end": null,
        "duration": 73.52,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Procedural)",
        "bins": {
            "videolen": 3,
            "qcenter": 7,
            "qlen": 8,
            "dataset": "anet",
            "qsemtype": "HAP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_3cQg4XOkC5Y.mp4",
        "question": " They have sparkling pom poms on the ground.",
        "answer": "17.64-74.28",
        "start": null,
        "end": null,
        "duration": 106.88,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 4,
            "qlen": 7,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_EWlt9TTOw30.mp4",
        "question": " a christmas tree is shown.",
        "answer": "0.0-11.14",
        "start": null,
        "end": null,
        "duration": 82.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_j7vUMNMB4Yo.mp4",
        "question": " A silver ladder is against the house.",
        "answer": "20.07-21.0",
        "start": 0.0,
        "end": 93.35,
        "duration": 93.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_mjKcoY18QG0.mp4",
        "question": "A gold telephone with several white buttons on it is lit up ringing next to a bed in a hotel room.",
        "answer": "0.0-3.59",
        "start": null,
        "end": null,
        "duration": 143.73,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_SSJjjggYBxc.mp4",
        "question": " Several tracks from shoes are seen in the sidewalk.",
        "answer": "8.02-19.26",
        "start": null,
        "end": null,
        "duration": 53.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_qVuRcevXgMk.mp4",
        "question": "A close up of a contact lens holder.",
        "answer": "0.0-4.04",
        "start": null,
        "end": null,
        "duration": 80.81,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_7Eh6c1eYMFk.mkv",
        "question": "a vacuum is shown standing in a kitchen.",
        "answer": "0.0-5.99",
        "start": null,
        "end": null,
        "duration": 70.51,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_6q3EIv2X8BQ.mp4",
        "question": "We see baby chick and goats.",
        "answer": "0.0-4.17",
        "start": null,
        "end": null,
        "duration": 33.34,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ZH8hnmjRDsI.mp4",
        "question": "A yellow plane is flying in the sky.",
        "answer": "0.0-9.45",
        "start": null,
        "end": null,
        "duration": 59.05,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_wPYr19iFxhw.mp4",
        "question": "A red machine is seen on the ground.",
        "answer": "0.0-15.28",
        "start": null,
        "end": null,
        "duration": 56.61,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_0JgcRWHCi4c.mp4",
        "question": " An orange and white cat comes into the room on the right on top of the couch.",
        "answer": "9.68-22.32",
        "start": null,
        "end": null,
        "duration": 22.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 8,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_s60we-9PBhw.mp4",
        "question": "A white kitten is sleeping on the bed.",
        "answer": "0.0-16.33",
        "start": null,
        "end": null,
        "duration": 79.67,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_WT7ZtXsTslM.mkv",
        "question": "Several layers of a cake are being shown.",
        "answer": "0.0-3.46",
        "start": null,
        "end": null,
        "duration": 69.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ux3h_qEusvw.mp4",
        "question": "A close up of potatoes are shown as well as a peeler.",
        "answer": "0.0-47.03",
        "start": null,
        "end": null,
        "duration": 154.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_v3t4Z5cEgZM.mp4",
        "question": " She has a glass ash tray on a table next to her.",
        "answer": "21.21-44.46",
        "start": null,
        "end": null,
        "duration": 51.11,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 6,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_Gl6EMAgTNKo.mp4",
        "question": " Plates of food are shown on a table.",
        "answer": "39.34-39.97",
        "start": null,
        "end": null,
        "duration": 62.95,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_6UqWORrn3KI.mp4",
        "question": " A water jug, five lemons, some sugar and a boiling pot are placed on the stove top.",
        "answer": "5.61-8.86",
        "start": null,
        "end": null,
        "duration": 59.05,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_D_y9uXMbImA.mp4",
        "question": " A white car is parked on the street.",
        "answer": "44.39-44.89",
        "start": null,
        "end": null,
        "duration": 49.6,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_frePM0YGtQE.mp4",
        "question": "A vacant kitchen is shown with a black shopping bag hanging down from the wood.",
        "answer": "0.0-5.26",
        "start": null,
        "end": null,
        "duration": 175.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_5n8wY8hwy3Y.mp4",
        "question": "  A toy dump truck is under the pump.",
        "answer": "41.2-50.85",
        "start": null,
        "end": null,
        "duration": 175.33,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_fxgbk_Kk4Rw.mp4",
        "question": " The other vacuum is shown with its attachment parts laid out in front of it.",
        "answer": "28.94-32.09",
        "start": null,
        "end": null,
        "duration": 125.83,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 6,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ay_YB-S4qR0.mp4",
        "question": "A close up of a dart board is shown.",
        "answer": "0.0-8.48",
        "start": null,
        "end": null,
        "duration": 34.62,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_JOBSEatasv4.mp4",
        "question": "a large towel is laid on the floor of a living room.",
        "answer": "0.0-12.7",
        "start": null,
        "end": null,
        "duration": 133.7,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_5wBo0Gd81-I.mp4",
        "question": " the cars are then started.",
        "answer": "29.52-111.52",
        "start": null,
        "end": null,
        "duration": 164.0,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 8,
            "qcenter": 4,
            "qlen": 7,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_dgRYwmcRpuo.mp4",
        "question": "  The sponge is ringed out.",
        "answer": "104.09-105.7",
        "start": null,
        "end": null,
        "duration": 161.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 8,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_U0d68z5HTwE.mp4",
        "question": " The mixture is covered by plastic wrap.",
        "answer": "66.24-73.25",
        "start": null,
        "end": null,
        "duration": 127.39,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 6,
            "qcenter": 5,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_t97xM9sY2yg.mp4",
        "question": " the food is then plated.",
        "answer": "80.4-130.73",
        "start": null,
        "end": null,
        "duration": 130.73,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 6,
            "qcenter": 8,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_z7zj8stU-kw.mp4",
        "question": " There is a closeup of the brush getting rinsed in the water.",
        "answer": "2.32-4.25",
        "start": null,
        "end": null,
        "duration": 4.64,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 0,
            "qcenter": 7,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_Z0eBz6QsI-c.mp4",
        "question": " the ball is considered out.",
        "answer": "24.1-41.19",
        "start": null,
        "end": null,
        "duration": 41.19,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 2,
            "qcenter": 7,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_el-ogdlS5nc.mp4",
        "question": " After he drops the lit matchstick in the pile of wood, it ignites and bursts into flames right away.",
        "answer": "3.08-4.17",
        "start": null,
        "end": null,
        "duration": 8.01,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_D0aZaiBAHxg.mp4",
        "question": " Eventually it is evened out.",
        "answer": "155.72-176.96",
        "start": null,
        "end": null,
        "duration": 176.96,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 8,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_7O9kkDxEvaY.mp4",
        "question": "  It looks great in the end.",
        "answer": "48.180661552824446-56.84066155282444",
        "start": 25.549338447175558,
        "end": 107.93933844717556,
        "duration": 82.39,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 4,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_WT7ZtXsTslM.mkv",
        "question": " They are then painted with frosting and dye.",
        "answer": "32.17-69.17",
        "start": null,
        "end": null,
        "duration": 69.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 3,
            "qcenter": 7,
            "qlen": 8,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_4usf67inE3w.mp4",
        "question": "The ball goes directly for the gutter but swirls back onto the lane because two black rails are up on the side.",
        "answer": "52.57-74.07",
        "start": null,
        "end": null,
        "duration": 159.29,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 7,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_lQWij22wbNU.mp4",
        "question": " the ball then becomes airborne.",
        "answer": "4.84-15.83",
        "start": null,
        "end": null,
        "duration": 32.3,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 1,
            "qcenter": 3,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_o-aSCtwxsTw.mp4",
        "question": " It spins in the air rapidly.",
        "answer": "31.44-40.07",
        "start": null,
        "end": null,
        "duration": 41.1,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 2,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_8-QcL1k5n6k.mp4",
        "question": " The man can easily fold up quickly for compact storage.",
        "answer": "48.37-49.89",
        "start": null,
        "end": null,
        "duration": 60.84,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 3,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_4j7sZBThR7s.mp4",
        "question": " Eventually he is done with the omelette.",
        "answer": "97.73-130.31",
        "start": null,
        "end": null,
        "duration": 130.31,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 6,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_optJ47P_5Ys.mp4",
        "question": " She is then shown with a brand new washer and dryer.",
        "answer": "13.49-15.51",
        "start": null,
        "end": null,
        "duration": 15.51,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 0,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_pnEYhDVXVJ0.mp4",
        "question": " A contact is removed from the case.",
        "answer": "5.62-18.89",
        "start": null,
        "end": null,
        "duration": 102.12,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 5,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_pnEYhDVXVJ0.mp4",
        "question": "A contact case is opened on a counter.",
        "answer": "0.0-11.74",
        "start": null,
        "end": null,
        "duration": 102.12,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 5,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ipcvgAb5y0U.mp4",
        "question": " The slices are marinated in sauce.",
        "answer": "9.89-27.53",
        "start": 0.0,
        "end": 86.03,
        "duration": 86.03,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 4,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_7hfaWQgcDyo.mp4",
        "question": "A grilled cheese sandwich is shown being pulled apart.",
        "answer": "0.0-5.41",
        "start": null,
        "end": null,
        "duration": 54.1,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 2,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_2oizmWFx4PA.mp4",
        "question": " It is then replaced with a new one.",
        "answer": "93.9-161.89",
        "start": null,
        "end": null,
        "duration": 161.89,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 8,
            "qcenter": 7,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_T7kOKW76EsA.mp4",
        "question": " A vacuum is shown afterwards moving in and out.",
        "answer": "32.15-75.18",
        "start": null,
        "end": null,
        "duration": 103.7,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 5,
            "qcenter": 5,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_n2wq_9TeNYM.mp4",
        "question": " Finally the race is finished.",
        "answer": "34.17-41.17",
        "start": null,
        "end": null,
        "duration": 41.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 2,
            "qcenter": 9,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_TIEzvhv6xaI.mp4",
        "question": " A man in a white shirt is standing next to the court.",
        "answer": "12.13-19.25",
        "start": null,
        "end": null,
        "duration": 19.25,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 0,
            "qcenter": 8,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_VvlJjaLwGqY.mp4",
        "question": "A woman is holding a piece of watermelon next to a pool.",
        "answer": "0.0-8.82",
        "start": null,
        "end": null,
        "duration": 135.7,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_E2nAOID5DLM.mp4",
        "question": " A young man waits on a racetrack.",
        "answer": "2.56-5.41",
        "start": null,
        "end": null,
        "duration": 28.47,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_A7oh6l1AIvs.mp4",
        "question": "A man is seated at equipment inside a gym.",
        "answer": "0.0-8.02",
        "start": 0.0,
        "end": 89.17,
        "duration": 89.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ANwaFSIHdW0.mp4",
        "question": "A woman is standing by a playground.",
        "answer": "0.0-6.2",
        "start": null,
        "end": null,
        "duration": 38.76,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_6TUA9ipKk9I.mp4",
        "question": " They stand in position, side by side ready to dive.",
        "answer": "10.49-36.07",
        "start": null,
        "end": null,
        "duration": 65.57,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_LIJBolW8k5o.mp4",
        "question": "A large group of people are seen sitting in the water looking around.",
        "answer": "0.0-36.75",
        "start": null,
        "end": null,
        "duration": 131.26,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 6,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_H_dERoTis5Y.mp4",
        "question": "People are standing in a tower.",
        "answer": "5.62-23.73",
        "start": null,
        "end": null,
        "duration": 124.9,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 6,
            "qcenter": 1,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_iubDO1DSMZk.mp4",
        "question": " The man poses with the baby.",
        "answer": "24.16-26.11",
        "start": null,
        "end": null,
        "duration": 77.93,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_Px08sPeSsG0.mp4",
        "question": "two men are sitting in frnot of the camera with paintings hanging in the white wall behind them.",
        "answer": "0.0-15.1",
        "start": 0.0,
        "end": 79.99,
        "duration": 79.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 3,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_YCqbvmEG-Uw.mp4",
        "question": " She has one door open and there is also a bush and statue behind her.",
        "answer": "0.0-10.71",
        "start": null,
        "end": null,
        "duration": 17.28,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 0,
            "qcenter": 3,
            "qlen": 9,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_xMEwcb1P6dQ.mp4",
        "question": "A girl is sitting inside a bedroom.",
        "answer": "0.0-5.84",
        "start": null,
        "end": null,
        "duration": 48.67,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 2,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_bJ6SpcLM7GE.mp4",
        "question": "Several people are holding lights in a dark arena.",
        "answer": "0.0-10.64",
        "start": null,
        "end": null,
        "duration": 85.1,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_W6JJ1L_EEBY.mp4",
        "question": "A small group of people are seen sitting on bikes before a start.",
        "answer": "0.0-28.87",
        "start": 0.0,
        "end": 99.57,
        "duration": 99.57,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 4,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_uJ_QCxMDfag.mp4",
        "question": " Another man is standing in the drive way watching him.",
        "answer": "7.26-20.74",
        "start": null,
        "end": null,
        "duration": 29.63,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 4,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_eCXiGAChev4.mp4",
        "question": " Another person is standing on the grass in front of them.",
        "answer": "10.92-12.17",
        "start": 0.0,
        "end": 83.96,
        "duration": 83.96,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 4,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_VFqkLp5mzBM.mp4",
        "question": " There is a polo match with horses.",
        "answer": "20.58-50.66",
        "start": null,
        "end": null,
        "duration": 79.16,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 3,
            "qcenter": 4,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ot-Y1sa-ujc.mp4",
        "question": "a woman is standing on a bridge in front of a crowd.",
        "answer": "0.0-33.34",
        "start": null,
        "end": null,
        "duration": 136.09,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 6,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_2GEZgHcA7zU.mp4",
        "question": "A man is seen standing on the edge of a diving board with his hands up.",
        "answer": "0.0-28.4",
        "start": 0.0,
        "end": 99.66,
        "duration": 99.66,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 4,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_VIROYxBPp70.mp4",
        "question": "Two guys stand in a boxing ring with their gloved hands covering their facial profiles .",
        "answer": "0.0-3.22",
        "start": null,
        "end": null,
        "duration": 37.85,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_VvlJjaLwGqY.mp4",
        "question": " She is sitting down at a table with food on it.",
        "answer": "20.35-42.07",
        "start": null,
        "end": null,
        "duration": 135.7,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 6,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_pem8BpCspUM.mp4",
        "question": " A person in the back spreads their arms out.",
        "answer": "2.59-4.12",
        "start": null,
        "end": null,
        "duration": 4.27,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 0,
            "qcenter": 7,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_FFyJjF4MjHM.mp4",
        "question": " A person in a blue jacket comes up behind them.",
        "answer": "29.39-35.2",
        "start": null,
        "end": null,
        "duration": 35.2,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Pose",
        "bins": {
            "videolen": 1,
            "qcenter": 9,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "HP"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_8ZA8UGBEx74.mp4",
        "question": "The camera opens on a dance floor in a darkened room.",
        "answer": "0.0-3.14",
        "start": null,
        "end": null,
        "duration": 104.65,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 5,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ml4aMGCJgP0.mp4",
        "question": " The PBA logo is shown with a message to watch the tour on ESPN.",
        "answer": "144.94-151.77",
        "start": null,
        "end": null,
        "duration": 151.77,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 7,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_-Z98HU6T7J8.mp4",
        "question": "A hardwood floor is shown on the ground.",
        "answer": "0.0-9.9",
        "start": null,
        "end": null,
        "duration": 131.96,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_sMVf7HDvsEc.mp4",
        "question": "  The birds look on at the finished Christmas tree.",
        "answer": "99.64-168.88",
        "start": null,
        "end": null,
        "duration": 168.88,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 8,
            "qcenter": 7,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_CfDdbeAk8LE.mp4",
        "question": "The credits of the clip are shown.",
        "answer": "0.0-1.23",
        "start": null,
        "end": null,
        "duration": 15.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 0,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_VcEW9F8TyqU.mp4",
        "question": "A display is set up for a game of beer pong.",
        "answer": "0.0-9.86",
        "start": null,
        "end": null,
        "duration": 82.13,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_Uc1_7BXtXZs.mp4",
        "question": "A GoPro logo appears on screen.",
        "answer": "0.0-3.36",
        "start": null,
        "end": null,
        "duration": 96.02,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_t_Creyg6ANs.mp4",
        "question": "\"Shuffleboard Olympics at Pembroke Pines\" appears on a black screen.",
        "answer": "0.0-7.82",
        "start": null,
        "end": null,
        "duration": 173.69,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_PagM71op4HU.mp4",
        "question": "  An ad for the dart shows on the screen.",
        "answer": "26.28-29.95",
        "start": null,
        "end": null,
        "duration": 30.56,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 1,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_mNM-JUC7ZEA.mp4",
        "question": "An introduction comes onto the screen for a video about home repair.",
        "answer": "0.0-2.45",
        "start": null,
        "end": null,
        "duration": 163.14,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_kElViDpjunQ.mp4",
        "question": "An introduction comes onto the screen for a video about leather care and cleaning.",
        "answer": "0.0-12.08",
        "start": null,
        "end": null,
        "duration": 120.77,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_75xhANnCOEg.mp4",
        "question": "A grey screen appears with black letters about the video about a Dojo.",
        "answer": "0.0-3.45",
        "start": null,
        "end": null,
        "duration": 137.97,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_oSoi5owiybU.mp4",
        "question": " We see a paper with a head line and a cityscape.",
        "answer": "10.43-24.22",
        "start": null,
        "end": null,
        "duration": 61.32,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 3,
            "qcenter": 2,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ulopyhvgyQg.mp4",
        "question": "A \"Top Dog Express Car Wash\" logo appears on screen.",
        "answer": "0.0-2.84",
        "start": null,
        "end": null,
        "duration": 40.57,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 2,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_38ZxXyECPPU.mp4",
        "question": " A black screen appears with a website address in white letters.",
        "answer": "108.25-112.18",
        "start": null,
        "end": null,
        "duration": 112.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 5,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_lyjz4sNglQg.mp4",
        "question": "A large christmas tree is shown with people walking in and out of frame.",
        "answer": "1.12-40.83",
        "start": null,
        "end": null,
        "duration": 111.87,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 5,
            "qcenter": 1,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ZhUC4qTGdHY.mp4",
        "question": " We see the ending title screens.",
        "answer": "145.39-164.28",
        "start": null,
        "end": null,
        "duration": 164.28,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 8,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_iMATWwGyAUM.mp4",
        "question": "The credits of the clip is shown.",
        "answer": "0.89-27.61",
        "start": null,
        "end": null,
        "duration": 178.1,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_c-C_9InvwKE.mkv",
        "question": " The home of the person is dirty and very old.",
        "answer": "55.51-73.04",
        "start": null,
        "end": null,
        "duration": 73.04,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 3,
            "qcenter": 8,
            "qlen": 3,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_suxZhXSVNKY.mkv",
        "question": " The logo \"Wonder Land Productions\" is shown on the screen.",
        "answer": "109.07-113.03",
        "start": null,
        "end": null,
        "duration": 113.03,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 5,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_akJbB6LWP34.mkv",
        "question": " The Gooroo logo appears on screen again.",
        "answer": "49.8-55.95",
        "start": null,
        "end": null,
        "duration": 55.95,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 2,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_JgDfOMDfNZs.mp4",
        "question": "A sign is shown by the side of the road.",
        "answer": "0.0-7.4",
        "start": null,
        "end": null,
        "duration": 46.26,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 2,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_RPkH81M6-NE.mp4",
        "question": "  A still picture of a book about how to start sailing appears with a link to the online shop underneath it.",
        "answer": "139.15-143.45",
        "start": null,
        "end": null,
        "duration": 143.45,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 7,
            "qcenter": 9,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_oS7Twj3Pou0.mp4",
        "question": "Man is carrying an umbrella that is brown in color.",
        "answer": "0.0-13.27",
        "start": null,
        "end": null,
        "duration": 37.92,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_b1QkoG9hxk8.mp4",
        "question": " The bartender describes the ingredients of the mudslide chocolate syrup, Kahlua, Bailey's and ice.",
        "answer": "64.35-77.53",
        "start": null,
        "end": null,
        "duration": 77.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 9,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_8-QcL1k5n6k.mp4",
        "question": " The machine has a multi functional on board computer.",
        "answer": "41.06-48.06",
        "start": null,
        "end": null,
        "duration": 60.84,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 7,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_Iq9cAZxki9Y.mp4",
        "question": "  A woman gives the name for scissors in Korean.",
        "answer": "10.71-11.3",
        "start": null,
        "end": null,
        "duration": 39.66,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_xQljKBB3498.mp4",
        "question": " She shows a bottle of orange face wash.",
        "answer": "17.6-56.4",
        "start": 0.0,
        "end": 90.23,
        "duration": 90.23,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_EqSXihtiv5g.mp4",
        "question": "Materials to make a gift pack is shown.",
        "answer": "0.0-13.49",
        "start": null,
        "end": null,
        "duration": 93.02,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ItukN-TWrJM.mkv",
        "question": " She shows off scissors and colored pink ribbon.",
        "answer": "20.31-47.38",
        "start": null,
        "end": null,
        "duration": 150.41,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 7,
            "qcenter": 2,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_Yzb_4XMgcM4.mp4",
        "question": "Canada baton twirling logo in pink.",
        "answer": "0.0-12.18",
        "start": null,
        "end": null,
        "duration": 143.27,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 7,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_6Y8wppTQFPo.mp4",
        "question": "This is how your folding bike looks straight out of the box.",
        "answer": "0.0-13.53",
        "start": null,
        "end": null,
        "duration": 100.22,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 5,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_krFle3KU4Ts.mp4",
        "question": " The accordian has ivory keys he plays with his fingers.",
        "answer": "43.61-65.09",
        "start": null,
        "end": null,
        "duration": 65.09,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 8,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_P9qhbSYblG4.mp4",
        "question": "A close up is seen of a fancy bowling ball.",
        "answer": "0.0-12.73",
        "start": null,
        "end": null,
        "duration": 115.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 5,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_IfKGdI5egKc.mp4",
        "question": " Not to mention, there's another dog that bigger and fluffier than all of the other dogs, except he's easy to work with.",
        "answer": "43.89-112.55",
        "start": null,
        "end": null,
        "duration": 112.55,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 5,
            "qcenter": 6,
            "qlen": 9,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ZVIi4lPU6h0.mp4",
        "question": "different pumpkins with famous people sculpt in pumpkins.",
        "answer": "0.0-10.06",
        "start": null,
        "end": null,
        "duration": 69.41,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_3Y_4Azzta6Q.mp4",
        "question": " A cake shaped like a heart wearing panties is shown.",
        "answer": "5.15-10.31",
        "start": null,
        "end": null,
        "duration": 171.81,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_WT7ZtXsTslM.mkv",
        "question": " They are shaped into what appears to be a shoe.",
        "answer": "8.99-31.13",
        "start": null,
        "end": null,
        "duration": 69.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 2,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_8-QcL1k5n6k.mp4",
        "question": " The foam seat is contoured and looks comfortable.",
        "answer": "29.51-40.76",
        "start": null,
        "end": null,
        "duration": 60.84,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 5,
            "qlen": 2,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_8-QcL1k5n6k.mp4",
        "question": " The machine has transport wheels for easy transport the rowing machine to exercise.",
        "answer": "52.93-59.32",
        "start": null,
        "end": null,
        "duration": 60.84,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 9,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_HpjomKhpIdk.mp4",
        "question": " The camera man continues to walk around on the roof.",
        "answer": "35.23-61.9",
        "start": null,
        "end": null,
        "duration": 63.48,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 7,
            "qlen": 6,
            "dataset": "anet",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_eM2miz5uf8Q.mp4",
        "question": "A man walks up to an ice covered truck.",
        "answer": "0.0-5.34",
        "start": null,
        "end": null,
        "duration": 76.26,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_kbe4iowYMqM.mp4",
        "question": "a woman stands in a kitchen a begins talking.",
        "answer": "0.0-40.6",
        "start": null,
        "end": null,
        "duration": 139.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 6,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "anet",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_sY31L_r7dsk.mp4",
        "question": " They stir the food in the bowl on the table.",
        "answer": "25.86-55.61",
        "start": null,
        "end": null,
        "duration": 55.61,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 2,
            "qcenter": 7,
            "qlen": 8,
            "dataset": "anet",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_ELiXlJUBzzw.mp4",
        "question": "A man is spraying a hose with a nozzle onto his car.",
        "answer": "6.15-19.13",
        "start": null,
        "end": null,
        "duration": 136.63,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "anet",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/ActivityNet/videos/v_Z0mxEFOm_Wc.mp4",
        "question": " the man then wipes the piece of wood clean.",
        "answer": "22.972974026480202-57.9729740264802",
        "start": 30.6170259735198,
        "end": 119.2070259735198,
        "duration": 88.59,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/anet_test.json",
        "dataset_name": "anet",
        "qsemtype": "Human Action (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 5,
            "dataset": "anet",
            "qsemtype": "HAS"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/bbd99850-bcb0-460e-8a40-056f1e618f88.mp4",
        "question": "where was eggs?",
        "answer": "0.81-12.09",
        "start": 0.93,
        "end": 70.88,
        "duration": 69.94999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/e5e98fec-82b8-4401-9a7a-42eae3f51e55.mp4",
        "question": "What did I put in the container?",
        "answer": "22.62-25.02",
        "start": 156.0,
        "end": 229.74,
        "duration": 73.74000000000001,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/584e542e-1968-4cb8-bd34-aebe80faffdf.mp4",
        "question": "Where did I put the nylon?",
        "answer": "6.94-8.86",
        "start": 6.26,
        "end": 79.17,
        "duration": 72.91,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/3231822a-fc8b-4207-b0b8-5cbb1344cb2f.mp4",
        "question": "What kitchen tool did I cut the springer onions with?",
        "answer": "5.67-14.19",
        "start": 3.33,
        "end": 143.14,
        "duration": 139.80999999999997,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/3640bd0e-d041-4b6e-b0a8-49b078c82312.mp4",
        "question": "Where did i put the pencil?",
        "answer": "25.49-26.51",
        "start": 255.49,
        "end": 329.05,
        "duration": 73.56,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/81ad10fe-c74e-4359-8779-186f46680e2c.mp4",
        "question": "Where was the pack of salt before i picked it ?",
        "answer": "86.83-91.51",
        "start": 311.09,
        "end": 443.58,
        "duration": 132.49,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/eeca9b8b-d737-4a70-ad68-0cb49cf36a67.mp4",
        "question": "Where was the paint can before I picked it?",
        "answer": "18.74-22.16",
        "start": 190.36,
        "end": 256.72,
        "duration": 66.36000000000001,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/99679e4d-1396-4248-97f4-97c9b0ed5336.mp4",
        "question": "Where is the nut before I picked a bolt?",
        "answer": "85.83-85.83",
        "start": 90.93,
        "end": 225.17,
        "duration": 134.23999999999998,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/1cac2aa7-4f65-4a50-88b9-e1f6e5c927f8.mp4",
        "question": "How many plates did I pick from the cupboard?",
        "answer": "21.65-28.61",
        "start": 108.37,
        "end": 184.08,
        "duration": 75.71000000000001,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/8acaf6f6-5396-4df6-98e6-13baea8f8af8.mp4",
        "question": "Where was the oven peel before I put it into the oven?",
        "answer": "79.52-83.18",
        "start": 569.8,
        "end": 698.3,
        "duration": 128.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/83f8791f-a654-4d07-89b6-2e7660b1663c.mp4",
        "question": "How many bicycles were packed outside the house?",
        "answer": "17.54-30.32",
        "start": 111.28,
        "end": 189.16,
        "duration": 77.88,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/cab983c1-d36e-4afa-8116-1e2bde4a4a4c.mp4",
        "question": "What vegetable did i chop on the chopping board?",
        "answer": "79.56-96.48",
        "start": 110.46,
        "end": 242.39,
        "duration": 131.93,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5e1a8326-b006-423e-8294-0f9559c8eb18.mp4",
        "question": "How many power tools are on the work becnh?",
        "answer": "26.84-30.44",
        "start": 160.84,
        "end": 239.02,
        "duration": 78.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/d752aedb-caf6-4e14-a98c-26d4e37eb144.mp4",
        "question": "In what location did I drop the red can of water?",
        "answer": "87.33-90.75",
        "start": 106.89,
        "end": 243.6,
        "duration": 136.70999999999998,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/6e73e4ca-d147-40ea-8587-035e8f2850c7.mp4",
        "question": "How many red cups are on the floor?",
        "answer": "22.9-27.94",
        "start": 551.12,
        "end": 619.18,
        "duration": 68.05999999999995,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/1c597fc1-7bd0-4325-abbc-645e3ec71866.mp4",
        "question": "What did I pick from the fridge?",
        "answer": "81.31-84.67",
        "start": 159.71,
        "end": 288.81,
        "duration": 129.1,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/61a0bd1c-c14b-41bb-a97e-05cd58207e5a.mp4",
        "question": "How many cups are on the work table?",
        "answer": "23.54-30.74",
        "start": 191.08,
        "end": 262.82,
        "duration": 71.73999999999998,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/cab983c1-d36e-4afa-8116-1e2bde4a4a4c.mp4",
        "question": "Where was the pan before I picked it?",
        "answer": "86.07-86.19",
        "start": 50.79,
        "end": 175.54,
        "duration": 124.75,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/e8e79a66-a5cc-48aa-93b3-79400c04cc1f.mp4",
        "question": "How many bottles were on the countertop?",
        "answer": "16.15-25.21",
        "start": 10.79,
        "end": 73.94,
        "duration": 63.15,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/35cd9ace-642f-4550-8e63-a5c2caae89ed.mp4",
        "question": "Where were the gloves before I picked the wood ",
        "answer": "92.12-94.64",
        "start": 114.82,
        "end": 250.38,
        "duration": 135.56,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/9466f5f0-09f2-4b9f-bb4a-3de270fd425b.mp4",
        "question": "How many paddles are on the wall?",
        "answer": "26.46-31.02",
        "start": 211.92,
        "end": 286.87,
        "duration": 74.95000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/903e0bf6-db7e-4b1c-8cb9-867317963fde.mp4",
        "question": "Where did I put the spanner?",
        "answer": "82.81-83.83",
        "start": 307.43,
        "end": 432.12,
        "duration": 124.69,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/d7b8f461-db42-4365-9f89-83f923528293.mp4",
        "question": "How much cauliflower did I put in the pan?",
        "answer": "19.47-24.15",
        "start": 166.71,
        "end": 233.08,
        "duration": 66.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/70cef020-51e7-429e-af75-f87747b3daad.mp4",
        "question": "what did I put in the dough mixer?",
        "answer": "50.67-51.69",
        "start": 21.33,
        "end": 154.79,
        "duration": 133.45999999999998,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/2bbc6cdf-b662-498e-9a9f-231dd5ac2a9e.mp4",
        "question": "How many blue spirit level is on the brick?",
        "answer": "0.62-4.76",
        "start": 0.28,
        "end": 61.21,
        "duration": 60.93,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/3cc0550b-666e-42b7-833a-47f8f9b686ae.mp4",
        "question": "where was the screw driver after i picked it?",
        "answer": "86.58-86.58",
        "start": 300.72,
        "end": 436.22,
        "duration": 135.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/cf1470f1-9a03-4944-95dd-7f8410bb6cc8.mp4",
        "question": "How many bottles did I pick?",
        "answer": "26.17-29.05",
        "start": 675.41,
        "end": 746.45,
        "duration": 71.04000000000008,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/a18c5454-8d7f-4380-944a-21854635d7f9.mp4",
        "question": "Where was the tile before I cut it?",
        "answer": "75.48-94.08",
        "start": 309.72,
        "end": 431.49,
        "duration": 121.76999999999998,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/453bf120-65a3-4616-bbd7-51bafdaac44d.mp4",
        "question": "How many socket sets did i remove from the pack ?",
        "answer": "21.58-28.0",
        "start": 77.96,
        "end": 156.55,
        "duration": 78.59000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/45d01186-d09a-408c-a00d-481a2d8d9749.mp4",
        "question": "what trash did I throw?",
        "answer": "83.55-98.55",
        "start": 131.61,
        "end": 271.23,
        "duration": 139.62,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/a538b7bc-5ec2-496a-8bbe-9d6d38381a39.mp4",
        "question": "How many cigarette sticks did I pick up from the phone?",
        "answer": "29.38-31.66",
        "start": 72.14,
        "end": 151.03,
        "duration": 78.89,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5c2b2be2-03c9-4169-99d1-a7df7639b946.mp4",
        "question": "Where was the scissors before I picked it?",
        "answer": "90.77-91.91",
        "start": 59.17,
        "end": 190.3,
        "duration": 131.13,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/53c86be4-190d-4410-8750-179a7edc70b3.mp4",
        "question": "How many chairs were in the corridor?",
        "answer": "22.61-29.99",
        "start": 1.03,
        "end": 75.15,
        "duration": 74.12,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/a3aea4be-3594-4372-98d7-cfbb9cc06170.mp4",
        "question": "Where did i put wood?",
        "answer": "63.97-64.93",
        "start": 399.05,
        "end": 478.51,
        "duration": 79.45999999999998,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/59c01c97-9312-47f8-b911-dd789978714b.mp4",
        "question": "how many times did l fetched flour with measuring spoon",
        "answer": "75.75-86.19",
        "start": 186.81,
        "end": 308.49,
        "duration": 121.68,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/eaf8d34a-0e20-45d0-a288-569df047461e.mp4",
        "question": "What rag did I use to clean the carburetor?",
        "answer": "63.78-87.12",
        "start": 131.04,
        "end": 254.29,
        "duration": 123.25,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/b8654118-84a4-4167-83c9-f268cc15f7b2.mp4",
        "question": "How many screwdrivers did pick from the drawer ",
        "answer": "24.15-31.83",
        "start": 346.23,
        "end": 419.3,
        "duration": 73.07,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5a93f209-59d4-4950-80d2-c8e43cc2fe7f.mp4",
        "question": "what did i pour in the dough mixer?",
        "answer": "33.96-35.94",
        "start": 118.08,
        "end": 200.29,
        "duration": 82.21,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5e59031d-0deb-4557-a3e1-ba0ba2bb5465.mp4",
        "question": "How many towels did I take from  the hanging line?",
        "answer": "79.24-82.24",
        "start": 34.76,
        "end": 161.67,
        "duration": 126.91,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/b8654118-84a4-4167-83c9-f268cc15f7b2.mp4",
        "question": "What surface did I write on?",
        "answer": "20.76-27.9",
        "start": 177.12,
        "end": 250.19,
        "duration": 73.07,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/da0092ba-0247-4438-9172-4f60f00be608.mp4",
        "question": "How many bowls did I collect?",
        "answer": "37.18-40.48",
        "start": 212.84,
        "end": 301.0,
        "duration": 88.16,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5ccb96c6-714f-4a93-9352-540899b27a4d.mp4",
        "question": "Where did I put my dog plate?",
        "answer": "79.78-80.68",
        "start": 1005.32,
        "end": 1131.7,
        "duration": 126.38,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/96453857-2454-418f-bbd6-3f5f8b3eadbd.mp4",
        "question": "How many bottles did you see?",
        "answer": "0.0-17.34",
        "start": 0.0,
        "end": 76.06,
        "duration": 76.06,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/751201ad-5397-4956-a4f2-d73fb969b6c5.mp4",
        "question": "What time was displayed on my phone screen?",
        "answer": "39.74-46.4",
        "start": 312.94,
        "end": 408.97,
        "duration": 96.03000000000003,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Environment State",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "ES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/86c3b190-a57a-4b88-a3be-4d8d47c8d867.mp4",
        "question": "where did l throw the dust",
        "answer": "78.68-83.96",
        "start": 162.04,
        "end": 292.48,
        "duration": 130.44000000000003,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/67db788f-6307-416f-8385-d4053e5777b9.mp4",
        "question": "how many items did i pick from the slab?",
        "answer": "22.52-24.38",
        "start": 5.32,
        "end": 68.71,
        "duration": 63.38999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/a3daf5dc-0809-4217-b7e2-fd868b212dfe.mp4",
        "question": "In what location did I see car boot?",
        "answer": "1.5-1.5",
        "start": 6.36,
        "end": 96.03,
        "duration": 89.67,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/4c4d7210-b39d-4659-b433-befd181482c2.mp4",
        "question": "What did I pick from the closet",
        "answer": "78.54-87.12",
        "start": 12.42,
        "end": 147.45,
        "duration": 135.03,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/95daa74b-1edf-4f33-96ff-e0c7eb0c0dbb.mp4",
        "question": "How many nails did I collect from my apprentice?",
        "answer": "18.73-23.59",
        "start": 69.35,
        "end": 132.93,
        "duration": 63.58000000000001,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/3803f332-0ac4-4f11-92c7-319318859908.mp4",
        "question": "Where is the bed area rug?",
        "answer": "36.84-41.64",
        "start": 861.36,
        "end": 957.94,
        "duration": 96.58000000000004,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/f2e7ca6e-d5f5-4342-b870-3cfa9174005a.mp4",
        "question": "What socket did I touch?",
        "answer": "88.72-92.5",
        "start": 269.66,
        "end": 402.86,
        "duration": 133.2,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/ed0a0e94-c79b-462d-a64b-238f26fd6fc6.mp4",
        "question": "How many trash bins were near cashier desk?",
        "answer": "22.11-25.83",
        "start": 279.09,
        "end": 358.05,
        "duration": 78.96000000000004,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/ab5213e0-11d5-4c5a-ade4-0f77a837e5bd.mp4",
        "question": "where is the basket",
        "answer": "61.01-62.15",
        "start": 380.29,
        "end": 472.71,
        "duration": 92.41999999999996,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/cbcad1bb-1b90-4838-84d7-887ee99dfdd0.mp4",
        "question": "Where did I put the leek cover?",
        "answer": "14.5-16.12",
        "start": 5.06,
        "end": 125.99,
        "duration": 120.92999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/1c597fc1-7bd0-4325-abbc-645e3ec71866.mp4",
        "question": "How many plates did i take from the top shelf?",
        "answer": "19.52-26.54",
        "start": 213.46,
        "end": 276.8,
        "duration": 63.34,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/1d122be0-830e-42ca-a6a4-b8ae67b0e3bc.mp4",
        "question": "Where is the square orange torch?",
        "answer": "58.92-62.7",
        "start": 300.3,
        "end": 390.35,
        "duration": 90.05000000000001,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/4ecd1707-cce9-46bf-9846-11d031f79556.mp4",
        "question": "Where did I put the small pieces of wooden tiles?",
        "answer": "71.93-74.87",
        "start": 113.11,
        "end": 234.21,
        "duration": 121.10000000000001,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/e5e98fec-82b8-4401-9a7a-42eae3f51e55.mp4",
        "question": "What color is the keg on the cabinet?",
        "answer": "20.85-23.73",
        "start": 275.55,
        "end": 345.09,
        "duration": 69.53999999999996,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/c1ca1e42-aee7-4837-a0f9-4d609bf06ceb.mp4",
        "question": "How many trash bags did I put in the trash chute?",
        "answer": "41.86-41.86",
        "start": 276.56,
        "end": 362.16,
        "duration": 85.60000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/c7873f07-7b9c-4794-9a56-fdebeeceee68.mp4",
        "question": "I what location did I see the wireless mouse?",
        "answer": "47.96-51.62",
        "start": 12.1,
        "end": 151.09,
        "duration": 138.99,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 6,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5c2b2be2-03c9-4169-99d1-a7df7639b946.mp4",
        "question": "Where was the wire connector before I picked it?",
        "answer": "27.48-32.46",
        "start": 353.52,
        "end": 431.78,
        "duration": 78.25999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/992cee60-a8af-423f-8a40-5b14208fcc1a.mp4",
        "question": "what color was the towel I folded ?",
        "answer": "53.68-61.24",
        "start": 383.66,
        "end": 473.88,
        "duration": 90.21999999999997,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 4,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/a538b7bc-5ec2-496a-8bbe-9d6d38381a39.mp4",
        "question": "How many white planks did I carry out of the house?",
        "answer": "73.44-92.94",
        "start": 337.62,
        "end": 458.97,
        "duration": 121.35000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/cf1470f1-9a03-4944-95dd-7f8410bb6cc8.mp4",
        "question": "In what area did I leave the basin?",
        "answer": "22.52-24.86",
        "start": 922.84,
        "end": 989.06,
        "duration": 66.21999999999991,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/8a855547-3574-4e67-a7ac-41b072984e3b.mp4",
        "question": "Where did I put the ceiling cornice?",
        "answer": "38.04-42.06",
        "start": 176.88,
        "end": 264.13,
        "duration": 87.25,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/992cee60-a8af-423f-8a40-5b14208fcc1a.mp4",
        "question": "What color is the chopping board i washed?",
        "answer": "78.2-89.24",
        "start": 55.42,
        "end": 180.53,
        "duration": 125.11,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/3e97dd3f-40c3-46c2-8c95-334799eeda0c.mp4",
        "question": "How many screws did I put in the device?",
        "answer": "21.9-28.8",
        "start": 2.7,
        "end": 75.94,
        "duration": 73.24,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/d37ab6fe-4f57-41ef-b6ff-cb193be15303.mp4",
        "question": "where was the refrigerator?",
        "answer": "1.97-8.09",
        "start": 156.25,
        "end": 192.97,
        "duration": 36.72,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/da0092ba-0247-4438-9172-4f60f00be608.mp4",
        "question": "In what location did I first see the Guitar?",
        "answer": "38.98-54.94",
        "start": 328.04,
        "end": 424.1,
        "duration": 96.06,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/2c2bda8d-69a3-4a90-9ad6-f6715bc99f39.mp4",
        "question": "What bedding material did I throw off the bed?",
        "answer": "0.78-3.36",
        "start": 14.4,
        "end": 150.1,
        "duration": 135.7,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 6,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/8a855547-3574-4e67-a7ac-41b072984e3b.mp4",
        "question": "How many objects did I put on the ground?",
        "answer": "3.76-8.26",
        "start": 2.6,
        "end": 70.77,
        "duration": 68.17,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/4c4d7210-b39d-4659-b433-befd181482c2.mp4",
        "question": "In what location did I see  a packet ",
        "answer": "0.7-29.68",
        "start": 386.18,
        "end": 421.28,
        "duration": 35.099999999999966,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 4,
            "qlen": 12,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5e59031d-0deb-4557-a3e1-ba0ba2bb5465.mp4",
        "question": "What did I put in the sink?",
        "answer": "42.07-43.03",
        "start": 348.95,
        "end": 445.0,
        "duration": 96.05000000000001,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/cf1470f1-9a03-4944-95dd-7f8410bb6cc8.mp4",
        "question": "What colour was the plastic I dropped on the floor?",
        "answer": "76.0-78.28",
        "start": 295.28,
        "end": 416.93,
        "duration": 121.65000000000003,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/9466f5f0-09f2-4b9f-bb4a-3de270fd425b.mp4",
        "question": "How many guitars are on the wall?",
        "answer": "23.2-24.28",
        "start": 24.74,
        "end": 93.28,
        "duration": 68.54,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/70bb4ddc-d071-4842-816a-5c3bd86260ea.mp4",
        "question": "In what location did I see the dog?",
        "answer": "26.89-28.45",
        "start": 439.79,
        "end": 479.3,
        "duration": 39.50999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5e1a8326-b006-423e-8294-0f9559c8eb18.mp4",
        "question": "Where did i put the pocket knife?",
        "answer": "4.5-7.92",
        "start": 12.42,
        "end": 156.2,
        "duration": 143.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 7,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/eaa17b24-b9df-468e-b682-6fabc0ff4408.mp4",
        "question": "What color is the cloth I picked on the floor?",
        "answer": "58.38-59.1",
        "start": 382.02,
        "end": 475.72,
        "duration": 93.70000000000005,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 4,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/7bf24899-4a05-46d4-b47d-36ce045643d8.mp4",
        "question": "How many cards did I move?",
        "answer": "73.18-90.1",
        "start": 112.4,
        "end": 233.59,
        "duration": 121.19,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5e1a8326-b006-423e-8294-0f9559c8eb18.mp4",
        "question": "In what location did I see the fire extinguisher?",
        "answer": "21.57-24.39",
        "start": 265.35,
        "end": 336.33,
        "duration": 70.97999999999996,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/9ab5fd9f-77e4-4438-a546-a4b6ed889f1a.mp4",
        "question": "what did l take in the dough drawer",
        "answer": "13.47-42.39",
        "start": 13.59,
        "end": 156.94,
        "duration": 143.35,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 3,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/eeca9b8b-d737-4a70-ad68-0cb49cf36a67.mp4",
        "question": "What color is the tool box on the cabinet?",
        "answer": "0.0-2.7",
        "start": 0.0,
        "end": 167.22,
        "duration": 167.22,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/4ecd1707-cce9-46bf-9846-11d031f79556.mp4",
        "question": "How many times did i hit the wall with the hammer?",
        "answer": "3.97-7.57",
        "start": 142.49,
        "end": 180.44,
        "duration": 37.94999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/70cef020-51e7-429e-af75-f87747b3daad.mp4",
        "question": "where is the tissue paper ",
        "answer": "44.97-45.75",
        "start": 154.17,
        "end": 252.62,
        "duration": 98.45000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/e4cf448f-e442-4e19-bf87-1eee8fbf59d8.mp4",
        "question": "what did l pour in the dough",
        "answer": "71.42-78.92",
        "start": 103.06,
        "end": 223.24,
        "duration": 120.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/fc4bfef7-e079-4783-92e1-b768cfac8125.mp4",
        "question": "what color of towel did I drop",
        "answer": "23.8-25.6",
        "start": 5.84,
        "end": 69.8,
        "duration": 63.959999999999994,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/eaf8d34a-0e20-45d0-a288-569df047461e.mp4",
        "question": "How many drawers did I open?",
        "answer": "7.37-32.75",
        "start": 447.31,
        "end": 475.21,
        "duration": 27.899999999999977,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 13,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/085f7a8b-e1e5-4e7b-a83d-5ea650edd9fe.mp4",
        "question": "in what location did I see a lorry?",
        "answer": "111.14-111.62",
        "start": 32.14,
        "end": 187.17,
        "duration": 155.02999999999997,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/60e7e14d-cbed-46d1-924d-6ce451ea7d7c.mp4",
        "question": "What cable did I remove?",
        "answer": "16.47-16.89",
        "start": 67.83,
        "end": 246.76,
        "duration": 178.93,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/a690c387-fc3c-4596-9ec5-42496139d90b.mp4",
        "question": "What color is the pliers?",
        "answer": "0.06-3.84",
        "start": 0.12,
        "end": 12.14,
        "duration": 12.020000000000001,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 0,
            "qcenter": 1,
            "qlen": 4,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/bccb07af-db56-4deb-9a5c-4fb2ee8a356f.mp4",
        "question": "How many yellow tuk-tuk are outside",
        "answer": "37.62-40.62",
        "start": 306.72,
        "end": 387.93,
        "duration": 81.20999999999998,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/c7873f07-7b9c-4794-9a56-fdebeeceee68.mp4",
        "question": "Did I leave the exit door open?",
        "answer": "78.59-83.21",
        "start": 69.37,
        "end": 200.3,
        "duration": 130.93,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5f70709f-d1a7-44ce-ade8-266a8cd41443.mp4",
        "question": "Where is the yellow cup?",
        "answer": "0.19-1.99",
        "start": 2.09,
        "end": 76.5,
        "duration": 74.41,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 3,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/6e7ed2e3-dfb7-4074-94dd-522cd66e882b.mp4",
        "question": "where did I last see the  bus?",
        "answer": "101.49-118.41",
        "start": 46.23,
        "end": 198.77,
        "duration": 152.54000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/b1bd830a-a738-4ebe-9e88-c348def0de90.mp4",
        "question": "What material was the bottle I carried to sink?",
        "answer": "136.69-139.69",
        "start": 214.61,
        "end": 383.71,
        "duration": 169.09999999999997,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/1ff34d9f-1c5a-40d8-98ee-8d3cbf48ebc3.mp4",
        "question": "How much salt did I add in the food?",
        "answer": "4.4-16.28",
        "start": 56.92,
        "end": 81.3,
        "duration": 24.379999999999995,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 1,
            "qcenter": 4,
            "qlen": 7,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/864371ec-e13b-44ad-8e24-034d7506065a.mp4",
        "question": "Did I  close the door of the store of tools?",
        "answer": "4.85-9.35",
        "start": 195.73,
        "end": 212.07,
        "duration": 16.340000000000003,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 4,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5438349a-2d91-4d73-b763-f10f04c77d37.mp4",
        "question": "where is the dough",
        "answer": "30.1-38.32",
        "start": 290.66,
        "end": 373.91,
        "duration": 83.25,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/ee379d11-2535-4300-9d9e-dc9d9c53d94f.mp4",
        "question": "where was the pot lid?",
        "answer": "78.73-84.91",
        "start": 306.17,
        "end": 431.32,
        "duration": 125.14999999999998,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/8bf16989-e870-44bb-863c-c6745e69f6fb.mp4",
        "question": "what was the color of the frying pan?",
        "answer": "21.06-21.06",
        "start": 25.68,
        "end": 91.72,
        "duration": 66.03999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/89f7ac43-956d-4d7e-b8a1-442ecff20ad6.mp4",
        "question": "How many detergents did you see?",
        "answer": "114.35-114.35",
        "start": 37.09,
        "end": 194.92,
        "duration": 157.82999999999998,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/3231822a-fc8b-4207-b0b8-5cbb1344cb2f.mp4",
        "question": "Did I wash the chopping board before putting a sachet on it?",
        "answer": "25.49-30.89",
        "start": 75.91,
        "end": 250.38,
        "duration": 174.47,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/a3aea4be-3594-4372-98d7-cfbb9cc06170.mp4",
        "question": "In what spot did I see the bag?",
        "answer": "5.85-14.73",
        "start": 453.57,
        "end": 475.32,
        "duration": 21.75,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 4,
            "qlen": 6,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/7c5b1a4e-076b-43d3-ac73-ed24e00db958.mp4",
        "question": "Where was the fork before I picked it?",
        "answer": "6.84-12.84",
        "start": 188.04,
        "end": 287.57,
        "duration": 99.53,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/b01fdd44-357c-4566-b487-d9ff21e56c2e.mp4",
        "question": "What color was the hand towel I wiped my hands with?",
        "answer": "0.01-2.05",
        "start": 143.99,
        "end": 145.29,
        "duration": 1.299999999999983,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 0,
            "qcenter": 7,
            "qlen": 23,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/ca304360-2402-4241-a6eb-5ff2f300546f.mp4",
        "question": "how many papers were in the file?",
        "answer": "78.87-108.87",
        "start": 345.15,
        "end": 475.78,
        "duration": 130.63,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 6,
            "qcenter": 7,
            "qlen": 3,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5e59031d-0deb-4557-a3e1-ba0ba2bb5465.mp4",
        "question": "Did I leave the fridge open?",
        "answer": "20.11-23.29",
        "start": 1099.49,
        "end": 1160.99,
        "duration": 61.5,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/1d019e7e-e300-4fbc-a7b3-4edf317c1798.mp4",
        "question": "In what table did i see the remote?",
        "answer": "17.88-21.78",
        "start": 423.12,
        "end": 448.35,
        "duration": 25.230000000000018,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 1,
            "qcenter": 7,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/00d9a297-d967-4d28-8e5a-6b891814ec65.mp4",
        "question": "Where was the piece of meat before I picked it up?",
        "answer": "108.72-111.72",
        "start": 231.48,
        "end": 379.87,
        "duration": 148.39000000000001,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 7,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/b69e6150-0309-4202-bf4a-9a342f80d6d7.mp4",
        "question": "What color is the colander?",
        "answer": "7.23-10.53",
        "start": 16.71,
        "end": 191.26,
        "duration": 174.54999999999998,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/e2171ff4-e32e-437f-9792-f37613e86598.mp4",
        "question": "How many screws did I pick?",
        "answer": "1.09-7.21",
        "start": 234.41,
        "end": 242.97,
        "duration": 8.560000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 10,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/810d230f-2771-4a2d-ad09-9b04714930d3.mp4",
        "question": "did i turn off faucet",
        "answer": "70.21-71.23",
        "start": 385.73,
        "end": 479.02,
        "duration": 93.28999999999996,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 4,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/3f268027-765d-4988-91d9-f0f948e6f9bc.mp4",
        "question": "Where was the dog?",
        "answer": "105.2-107.18",
        "start": 348.46,
        "end": 469.67,
        "duration": 121.21000000000004,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 6,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/a40dce18-488d-4acc-b754-fcd56c204db1.mp4",
        "question": "Where was the sponge?",
        "answer": "19.29-26.79",
        "start": 11.49,
        "end": 83.57,
        "duration": 72.08,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/498d6197-deb0-481c-9cfd-8d516122638d.mp4",
        "question": "What color is the wire I picked last?",
        "answer": "27.36-27.36",
        "start": 68.94,
        "end": 221.72,
        "duration": 152.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/2b19ee03-d94f-4c1f-822d-d4c00a2066cc.mp4",
        "question": "How many switch case did i hold?",
        "answer": "134.42-137.18",
        "start": 134.8,
        "end": 304.48,
        "duration": 169.68,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/39ec61c9-8725-47dc-8a18-f00e27b8ab2c.mp4",
        "question": "Did I weigh the sugar? ",
        "answer": "0.12-22.68",
        "start": 389.7,
        "end": 428.4,
        "duration": 38.69999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 1,
            "qcenter": 2,
            "qlen": 8,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/90602dc0-4c33-4b26-b4d5-c63105c40187.mp4",
        "question": "Where is the tap",
        "answer": "2.44-12.7",
        "start": 192.32,
        "end": 208.24,
        "duration": 15.920000000000016,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 9,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/43db99a3-61ce-4548-ba5a-faf4c91c72f1.mp4",
        "question": "Where did I drop the spring onions?",
        "answer": "10.21-11.95",
        "start": 132.53,
        "end": 173.26,
        "duration": 40.72999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/70cef020-51e7-429e-af75-f87747b3daad.mp4",
        "question": "What color bottle is on the sink",
        "answer": "31.55-49.73",
        "start": 149.17,
        "end": 243.84,
        "duration": 94.67000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/28c1f367-b80b-4072-a54c-fa17b207bf7b.mp4",
        "question": "How many phones did I hold in my hand?",
        "answer": "81.83-92.69",
        "start": 109.87,
        "end": 235.05,
        "duration": 125.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/522b72ce-f947-4cdb-8ebb-ebdfdbe6f04f.mp4",
        "question": "Did I close the cabinet?",
        "answer": "53.6-54.26",
        "start": 388.6,
        "end": 457.78,
        "duration": 69.17999999999995,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 3,
            "qcenter": 7,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/a35ac9e4-bb20-460e-9c9d-67806ab9d13f.mp4",
        "question": "In what part of the supermarket did I see the candies?",
        "answer": "9.18-20.7",
        "start": 92.52,
        "end": 233.57,
        "duration": 141.05,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5ccb96c6-714f-4a93-9352-540899b27a4d.mp4",
        "question": "What did I put in a dog plate?",
        "answer": "152.07-154.23",
        "start": 958.77,
        "end": 1133.56,
        "duration": 174.78999999999996,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5d466470-4de6-4318-9806-f5a0c24807de.mp4",
        "question": "what color was tom yum?",
        "answer": "4.0-4.66",
        "start": 88.46,
        "end": 116.39,
        "duration": 27.930000000000007,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/b9cd86ff-d01f-4faa-9d2b-c53799e47273.mp4",
        "question": "How many nuts did I pick from the black plastic material?",
        "answer": "0.93-12.27",
        "start": 252.39,
        "end": 267.0,
        "duration": 14.610000000000014,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 0,
            "qcenter": 4,
            "qlen": 11,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/9a13aee2-0dca-49f8-968f-8f53c5a62963.mp4",
        "question": "Did I leave the tap open",
        "answer": "9.67-12.07",
        "start": 3.47,
        "end": 52.65,
        "duration": 49.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/09fb5412-80b9-49f0-841b-561a331ced64.mp4",
        "question": "where is my seat?",
        "answer": "30.05-37.31",
        "start": 132.91,
        "end": 213.99,
        "duration": 81.08000000000001,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/093259bc-5b71-4204-be7b-5f7b5b5f20cb.mp4",
        "question": "What item did I push with the mopping stick?",
        "answer": "78.59-81.89",
        "start": 527.29,
        "end": 655.74,
        "duration": 128.45000000000005,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/6dd27c16-8717-4a64-8921-a6ebc7cdfb3d.mp4",
        "question": "What color is the fuel tank lid i closed",
        "answer": "23.84-27.44",
        "start": 302.44,
        "end": 376.44,
        "duration": 74.0,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/810d230f-2771-4a2d-ad09-9b04714930d3.mp4",
        "question": "How many trays did I pick from the countertop?",
        "answer": "20.85-24.21",
        "start": 35.25,
        "end": 193.7,
        "duration": 158.45,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/e1c79556-e8af-4e26-bc4c-633100277239.mp4",
        "question": "Did I open the cabinet drawer?",
        "answer": "66.22-67.18",
        "start": 299.24,
        "end": 415.75,
        "duration": 116.50999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 5,
            "qcenter": 5,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/37440fa1-f1a7-4781-b89b-e0dd385af2eb.mp4",
        "question": "Where is the blue bucket?",
        "answer": "0.0-27.9",
        "start": 0.0,
        "end": 178.95,
        "duration": 178.95,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/522b72ce-f947-4cdb-8ebb-ebdfdbe6f04f.mp4",
        "question": "What did I put in the trash bin?",
        "answer": "6.2-9.02",
        "start": 245.8,
        "end": 285.43,
        "duration": 39.629999999999995,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/a185abe1-ae2e-4ab4-aa5c-d2f45abfd7c9.mp4",
        "question": "what colour of the napkin did I pick form the table ? ",
        "answer": "0.03-2.85",
        "start": 38.91,
        "end": 44.54,
        "duration": 5.630000000000003,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 0,
            "qcenter": 2,
            "qlen": 7,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5438349a-2d91-4d73-b763-f10f04c77d37.mp4",
        "question": "How many parts did I cut the dough into? ",
        "answer": "9.67-13.81",
        "start": 57.77,
        "end": 102.48,
        "duration": 44.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5438349a-2d91-4d73-b763-f10f04c77d37.mp4",
        "question": "Did I sprinkle flour on the table? ",
        "answer": "37.53-39.99",
        "start": 317.31,
        "end": 398.49,
        "duration": 81.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/f32cb53d-4a80-499c-bb32-cefef3abe205.mp4",
        "question": "In what location did I see the cat?",
        "answer": "81.68-85.82",
        "start": 6.16,
        "end": 145.38,
        "duration": 139.22,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/44c0c128-8f6e-4dc0-9a12-77d580260cdc.mp4",
        "question": "What snack did I eat?",
        "answer": "26.65-31.63",
        "start": 50.03,
        "end": 127.12,
        "duration": 77.09,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/f31e8020-1bdb-4885-90f6-a84ad8a392c9.mp4",
        "question": "What color is the pick up truck?",
        "answer": "81.03-95.19",
        "start": 11.31,
        "end": 166.64,
        "duration": 155.32999999999998,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 7,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/1c597fc1-7bd0-4325-abbc-645e3ec71866.mp4",
        "question": "How many food spoons did I put in the orange bow?",
        "answer": "63.8-76.22",
        "start": 15.22,
        "end": 133.15,
        "duration": 117.93,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 5,
            "qcenter": 5,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/0b20e242-a496-4662-a3e7-645bcecdbe55.mp4",
        "question": "Did I leave the tap open",
        "answer": "31.05-31.65",
        "start": 82.95,
        "end": 250.93,
        "duration": 167.98000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 8,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/085f7a8b-e1e5-4e7b-a83d-5ea650edd9fe.mp4",
        "question": "who did I laugh at on the road?",
        "answer": "2.98-2.98",
        "start": 331.82,
        "end": 359.58,
        "duration": 27.75999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/c0a634a9-3dbe-44f8-9a04-7718d2a2762e.mp4",
        "question": "in what room did I see the machine?",
        "answer": "0.11-2.21",
        "start": 419.11,
        "end": 433.79,
        "duration": 14.680000000000007,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 0,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/742355b3-3123-4671-99e9-8a4612204b9c.mp4",
        "question": "where did I walked in the garden",
        "answer": "0.74-15.74",
        "start": 128.32,
        "end": 168.86,
        "duration": 40.54000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 5,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/67db788f-6307-416f-8385-d4053e5777b9.mp4",
        "question": "what color is the clothe?",
        "answer": "40.58-43.1",
        "start": 254.92,
        "end": 339.55,
        "duration": 84.63000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5d531ac1-010a-4e67-ba1a-96e485b14968.mp4",
        "question": "How much bell pepper did I put in the bowl?",
        "answer": "48.15-57.45",
        "start": 4.65,
        "end": 138.83,
        "duration": 134.18,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 6,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/59c01c97-9312-47f8-b911-dd789978714b.mp4",
        "question": "Did I weigh the content of the sack? ",
        "answer": "22.02-27.36",
        "start": 283.02,
        "end": 362.19,
        "duration": 79.17000000000002,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/badca5ee-61fc-4d80-9991-7ce29ddee7be.mp4",
        "question": "Who did I talk to at the door entrance?",
        "answer": "13.71-27.27",
        "start": 42.75,
        "end": 190.12,
        "duration": 147.37,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/20452467-184f-4160-9504-b83db092b9f6.mp4",
        "question": "What object was the woman in the room holding?",
        "answer": "10.47-23.43",
        "start": 23.55,
        "end": 126.75,
        "duration": 103.2,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/61a0bd1c-c14b-41bb-a97e-05cd58207e5a.mp4",
        "question": "where was the water pipe before i washed my hands",
        "answer": "135.76-136.6",
        "start": 9.38,
        "end": 170.51,
        "duration": 161.13,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 8,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/4ab42038-79a6-433c-905d-f1426561b9f8.mp4",
        "question": "What color is the wallet that I put in the shopping basket?",
        "answer": "4.49-8.09",
        "start": 374.89,
        "end": 412.67,
        "duration": 37.78000000000003,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 1,
            "qcenter": 1,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/a185abe1-ae2e-4ab4-aa5c-d2f45abfd7c9.mp4",
        "question": "how many are the boxes",
        "answer": "0.98-0.98",
        "start": 174.46,
        "end": 187.78,
        "duration": 13.319999999999993,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 0,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/7c34ddc3-9bd7-4266-b6e8-173b7392e49c.mp4",
        "question": "Did I leave the door open?",
        "answer": "4.37-22.73",
        "start": 325.27,
        "end": 380.11,
        "duration": 54.84000000000003,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 5,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/f31e8020-1bdb-4885-90f6-a84ad8a392c9.mp4",
        "question": "who did I interact with when I was moving the trolley?",
        "answer": "41.65-41.65",
        "start": 154.79,
        "end": 254.56,
        "duration": 99.77000000000001,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/3672773c-6ff8-47c2-9ef9-bb00c65814ef.mp4",
        "question": "where is plastic jug",
        "answer": "70.43-93.71",
        "start": 223.27,
        "end": 344.87,
        "duration": 121.6,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/9e225f1f-f50a-4236-8c32-934613b4b8d8.mp4",
        "question": "Where was the rag before I picked it up?",
        "answer": "26.8-30.46",
        "start": 313.88,
        "end": 390.72,
        "duration": 76.84000000000003,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5bff21b4-ac93-450f-a189-b2fb7cff4d99.mp4",
        "question": "What color was the stool",
        "answer": "19.42-21.64",
        "start": 6.2,
        "end": 160.07,
        "duration": 153.87,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 7,
            "qcenter": 1,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/5a93f209-59d4-4950-80d2-c8e43cc2fe7f.mp4",
        "question": "How many scoops of flour did I take?",
        "answer": "53.96-70.1",
        "start": 203.08,
        "end": 320.18,
        "duration": 117.1,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 5,
            "qcenter": 5,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/8c788340-5a9c-420d-8c29-ed7880d5d9ab.mp4",
        "question": "Did I turn the cooker knob?",
        "answer": "16.58-20.66",
        "start": 442.54,
        "end": 464.32,
        "duration": 21.779999999999973,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 1,
            "qcenter": 8,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/6ca9df87-89af-47b8-b24e-fb69bb6b58b4.mp4",
        "question": "When did I interact with the other player?",
        "answer": "9.91-16.15",
        "start": 44.63,
        "end": 208.84,
        "duration": 164.21,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 8,
            "qcenter": 0,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/864371ec-e13b-44ad-8e24-034d7506065a.mp4",
        "question": "Where did I see man X",
        "answer": "0.48-2.46",
        "start": 5.52,
        "end": 21.22,
        "duration": 15.7,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 0,
            "qcenter": 0,
            "qlen": 1,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/8a855547-3574-4e67-a7ac-41b072984e3b.mp4",
        "question": "Where did I put the measuring tape after opening the door?",
        "answer": "14.03-16.67",
        "start": 71.11,
        "end": 127.89,
        "duration": 56.78,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Complex)",
        "bins": {
            "videolen": 2,
            "qcenter": 2,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OEC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/998fdeef-3c22-4e5c-8cee-1f499246166b.mp4",
        "question": "What color is the golf ball i pick",
        "answer": "38.04-40.38",
        "start": 39.0,
        "end": 134.62,
        "duration": 95.62,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Attribute",
        "bins": {
            "videolen": 4,
            "qcenter": 4,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OA"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/f04e8671-a8f1-4bf8-965b-38f45679ac0a.mp4",
        "question": "How many wooden sticks did I hold?",
        "answer": "79.09-81.67",
        "start": 329.27,
        "end": 454.71,
        "duration": 125.44,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Counting",
        "bins": {
            "videolen": 6,
            "qcenter": 6,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/2c2bda8d-69a3-4a90-9ad6-f6715bc99f39.mp4",
        "question": "Did I open the door?",
        "answer": "23.17-25.69",
        "start": 358.97,
        "end": 433.98,
        "duration": 75.00999999999999,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Transition",
        "bins": {
            "videolen": 3,
            "qcenter": 3,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "OT"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/c7873f07-7b9c-4794-9a56-fdebeeceee68.mp4",
        "question": "I interacted with a driver woman while parking ",
        "answer": "128.61-128.61",
        "start": 328.95,
        "end": 479.21,
        "duration": 150.26,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Human Action (Complex)",
        "bins": {
            "videolen": 7,
            "qcenter": 8,
            "qlen": 0,
            "dataset": "egonlq",
            "qsemtype": "HAC"
        }
    },
    {
        "path": "./dataset/DATASET/EgoNLQ/nlq_raw_videos/e4cf448f-e442-4e19-bf87-1eee8fbf59d8.mp4",
        "question": "where is dough cutter",
        "answer": "60.0-77.7",
        "start": 12.3,
        "end": 130.01,
        "duration": 117.71,
        "question_type": "video temporal grounding",
        "source": "./dataset/DATASET/annotations/tvgbench/raw_data/nlq_r1_val.json",
        "qsemtype": "Object Existence (Simple)",
        "bins": {
            "videolen": 5,
            "qcenter": 5,
            "qlen": 2,
            "dataset": "egonlq",
            "qsemtype": "OES"
        }
    }
]